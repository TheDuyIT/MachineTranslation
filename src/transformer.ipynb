{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "chinhsua.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheDuyIT/MachineTranslation/blob/master/src/transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFG0NDRu5mYQ",
        "outputId": "f3e8c0d4-c25a-4ba4-d405-1543a6f375b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -q tfds-nightly\r\n",
        "# !pip install tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.8MB 5.9MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEATbN5DAYDT",
        "outputId": "d2b83aae-0021-4c4a-d744-8b83e8c66ead"
      },
      "source": [
        "!npx degit TheDuyIT/MachineTranslation -f"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 1 in 2.068s\n",
            "\u001b[36m> destination directory is not empty. Using --force, continuing\u001b[39m\n",
            "\u001b[36m> cloned \u001b[1mTheDuyIT/MachineTranslation\u001b[22m#\u001b[1mmaster\u001b[22m\u001b[39m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB9BXDZLyrMG"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjJJyJTZYebt"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "import time\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from src.process_data import DataFormatter, DataLoader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd1NWMxjfsDd"
      },
      "source": [
        "## Setup input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2MJM8-jV6IA"
      },
      "source": [
        "loader = DataLoader()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpF0MBnRaq2o"
      },
      "source": [
        "content_en = loader.np_load('lst_cn_all_except_1001')\n",
        "content_vn = loader.np_load('lst_vi_all_except_1001')\n",
        "content_en = loader.np_load('lst_cn')\n",
        "content_vn = loader.np_load('lst_vi')\n",
        "content_en = loader.np_load('lst_cn_all_with6k_except_1001')\n",
        "content_vn = loader.np_load('lst_vi_all_with6k_except_1001')\n",
        "def preproces_cn(s):\n",
        "  return re.sub('\\s+', ' ', ' '.join(s))\n",
        "for i in range(len(content_vn)):\n",
        "  content_vn[i] = content_vn[i].lower()\n",
        "  # content_en.append(i['en'].lower())\n",
        "  # content_vn.append(i['vn'].lower())\n",
        "for i in range(len(content_en)):\n",
        "  content_en[i] = preproces_cn(content_en[i])\n",
        "# content_en"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP0PoNkyDIHp",
        "outputId": "5a8ec0f7-f9bd-44cb-fad7-97df6621844a"
      },
      "source": [
        "print(len(content_en))\r\n",
        "print(len(content_vn))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14142\n",
            "14142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1guLOWvfLoC"
      },
      "source": [
        "a = tf.data.Dataset.from_tensor_slices(content_en)  # ==> [ 1, 2, 3 ]\n",
        "b = tf.data.Dataset.from_tensor_slices(content_vn)  # ==> [ 4, 5, 6 ]\n",
        "\n",
        "full_dataset = tf.data.Dataset.zip((a, b))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTGUJVei9wjc"
      },
      "source": [
        "train_size = int(0.8*0.9*len(full_dataset)) + 2\n",
        "val_size = int(0.8*0.1*len(full_dataset))\n",
        "test_size = int(0.2*len(full_dataset))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6Z3HImR9a-M"
      },
      "source": [
        "full_dataset = full_dataset.shuffle(buffer_size = 1000)\n",
        "train_examples = full_dataset\n",
        "test_dataset = full_dataset\n",
        "val_dataset = full_dataset\n",
        "# train_examples = full_dataset.take(train_size)\n",
        "# test_dataset = full_dataset.skip(train_size)\n",
        "# val_dataset = test_dataset.skip(val_size)\n",
        "# test_dataset = test_dataset.take(test_size)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVBg5Q8tBk5z"
      },
      "source": [
        "# tokenizer_vn = tfds.deprecated.text.SubwordTextEncoder.load_from_file('tokenizer_en')\n",
        "# tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.load_from_file('tokenizer_vn')\n",
        "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (en.numpy() for en, _ in train_examples), target_vocab_size=2**13)\n",
        "\n",
        "tokenizer_vn = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (vn.numpy() for _, vn in train_examples), target_vocab_size=2**13)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH_zOTI_3jg-"
      },
      "source": [
        "# for i in range(tokenizer_en.vocab_size):\r\n",
        "#   print(f'{i} ----> {tokenizer_en.decode([i])}')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9ddMZP5z3tp"
      },
      "source": [
        "# tokenizer_en.save_to_file('/content/drive/MyDrive/VinBigData/checkpoints/tokenizer_en')\r\n",
        "# tokenizer_vn.save_to_file('/content/drive/MyDrive/VinBigData/checkpoints/tokenizer_vn')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcRp7VcQ5m6g"
      },
      "source": [
        "BUFFER_SIZE = 2000\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZwnPr4R055s"
      },
      "source": [
        "def encode(lang1, lang2):\n",
        "  lang1 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
        "      lang1.numpy()) + [tokenizer_en.vocab_size+1]\n",
        "\n",
        "  lang2 = [tokenizer_vn.vocab_size] + tokenizer_vn.encode(\n",
        "      lang2.numpy()) + [tokenizer_vn.vocab_size+1]\n",
        "  \n",
        "  return lang1, lang2"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mah1cS-P70Iz"
      },
      "source": [
        "def tf_encode(en, vn):\n",
        "  result_en, result_vn = tf.py_function(encode, [en, vn], [tf.int64, tf.int64])\n",
        "  result_en.set_shape([None])\n",
        "  result_vn.set_shape([None])\n",
        "\n",
        "  return result_en, result_vn"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QEgbjntk6Yf"
      },
      "source": [
        "MAX_LENGTH = 190\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c081xPGv1CPI"
      },
      "source": [
        "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
        "  return tf.logical_and(tf.size(x) <= max_length,\n",
        "                        tf.size(y) <= max_length)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKIPFkLr-Qsz"
      },
      "source": [
        "train_dataset = train_examples.map(tf_encode)\n",
        "train_dataset = train_dataset.filter(filter_max_length)\n",
        "# cache the dataset to memory to get a speedup while reading from it.\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "val_dataset = val_dataset.map(tf_encode)\n",
        "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = test_dataset.map(tf_encode)\n",
        "test_dataset = test_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBQuibYA4n0n"
      },
      "source": [
        "## Positional encoding\n",
        "\n",
        "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence. \n",
        "\n",
        "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n",
        "\n",
        "See the notebook on [positional encoding](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) to learn more about it. The formula for calculating the positional encoding is as follows:\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhIOZjMNKujn"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rz82wEs5biZ"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kLCla68EloE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "b8a5308f-246e-4e9a-e160-a8b7b22957b3"
      },
      "source": [
        "pos_encoding = positional_encoding(50, 512)\n",
        "print (pos_encoding.shape)\n",
        "\n",
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 50, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_b4ou4TYqUN"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2i8-e1s8ti9"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVxS8OPI9uI0"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xluDl5cXYy4y"
      },
      "source": [
        "## Scaled dot product attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LazzUq3bJ5SH"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmzGPEy64qmA"
      },
      "source": [
        "## Multi-head attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSV3PPKsYecw"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    \n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdDqGayx67vv"
      },
      "source": [
        "## Point wise feed forward network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBqzJXGfHK3X"
      },
      "source": [
        "Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET7xLt0yCT6Z"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "## Encoder and decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFv-FNYUmvpn"
      },
      "source": [
        "### Encoder layer\n",
        "\n",
        "Each encoder layer consists of sublayers:\n",
        "\n",
        "1.   Multi-head attention (with padding mask) \n",
        "2.    Point wise feed forward networks. \n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
        "\n",
        "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncyS-Ms3i2x_"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    return out2"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LO_48Owmx_o"
      },
      "source": [
        "### Decoder layer\n",
        "\n",
        "Each decoder layer consists of sublayers:\n",
        "\n",
        "1.   Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2.   Multi-head attention (with padding mask). V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
        "3.   Point wise feed forward networks\n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
        "\n",
        "There are N decoder layers in the transformer.\n",
        "\n",
        "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SoX0-vd1hue"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "The `Encoder` consists of:\n",
        "1.   Input Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N encoder layers\n",
        "\n",
        "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpEox7gJ8FCI"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                            self.d_model)\n",
        "    \n",
        "    \n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-uO6ls8m2O5"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtT7PKzrXkNr"
      },
      "source": [
        " The `Decoder` consists of:\n",
        "1.   Output Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N decoder layers\n",
        "\n",
        "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5_d5-PLQXwY"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "    \n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    \n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "      \n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y54xnJnuYgJ7"
      },
      "source": [
        "## Create the Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PED3bIpOYkBu"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "    \n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "    \n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "    \n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    \n",
        "    return final_output, attention_weights"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "## Set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnJn5SLA2ahP"
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = tokenizer_en.vocab_size + 2\n",
        "target_vocab_size = tokenizer_vn.vocab_size + 2\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOmWW--yP3zx"
      },
      "source": [
        "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n",
        "\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYQdOO1axwEI"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r4scdulztRx"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgkDE7hzo8r5"
      },
      "source": [
        "## Loss and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxGJtoDuYIHL"
      },
      "source": [
        "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67oqVHiT0Eiu"
      },
      "source": [
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "def accuracy_function(real, pred):\n",
        "  # print('000000000000000000000000000')\n",
        "  # print(real)\n",
        "  # print('111111111111111111111111111')\n",
        "  # print(pred)\n",
        "  # print('222222222222222222222222222')\n",
        "  # print(tf.argmax(pred, axis=2))\n",
        "  # print('333333333333333333333333333')\n",
        "\n",
        "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "  # print(accuracies)\n",
        "  # print('333333333333333333333333333')\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
        "# def accuracy_function(real, pred):\n",
        "#   candidate = tf.argmax(pred, axis=2)\n",
        "#   # print(real.)\n",
        "#   print(real.numpy()[0][:-1])\n",
        "#   print(tokenizer_vn.decode(real.numpy()[0][:-1]))\n",
        "#   print(candidate.numpy()[0][:-1])\n",
        "#   print(tokenizer_vn.decode(candidate.numpy()[0][:-1]))\n",
        "#   # print(candidate)\n",
        "#   # score = bleu_score(real, candidate)\n",
        "#   score = 12\n",
        "#   print(score)\n",
        "#   return tf.constant(score)\n",
        "# # bleu_function('real', 'pred')\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPfZsplvJ0sG"
      },
      "source": [
        "# dir(tokenizer_vn)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggV3cc5-LyNX"
      },
      "source": [
        "# for i in content_vn[:12]:\r\n",
        "#   if 'mãnh_' in i:\r\n",
        "#     print(i)  "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIFfKbIEJ8P4"
      },
      "source": [
        "# for i in range(100000):\r\n",
        "#   print(tokenizer_vn._id_to_subword(i).encode('utf-8').decode('utf-8'))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOSeW1vcfTWa",
        "outputId": "a1dbd8a0-373e-4407-a412-aab9f2b97adf"
      },
      "source": [
        "from collections import Counter\r\n",
        "import math\r\n",
        "def n_gram_generator(sentence,n= 2,n_gram= False):\r\n",
        "    '''\r\n",
        "    N-Gram generator with parameters sentence\r\n",
        "    n is for number of n_grams\r\n",
        "    The n_gram parameter removes repeating n_grams \r\n",
        "    '''\r\n",
        "    sentence = sentence.lower() # converting to lower case\r\n",
        "    sent_arr = np.array(sentence.split()) # split to string arrays\r\n",
        "    length = len(sent_arr)\r\n",
        "\r\n",
        "    word_list = []\r\n",
        "    for i in range(length+1):\r\n",
        "        if i < n:\r\n",
        "            continue\r\n",
        "        word_range = list(range(i-n,i))\r\n",
        "        s_list = sent_arr[word_range]\r\n",
        "        string = ' '.join(s_list) # converting list to strings\r\n",
        "        word_list.append(string) # append to word_list\r\n",
        "        if n_gram:\r\n",
        "            word_list = list(set(word_list))\r\n",
        "    return word_list\r\n",
        "def bleu_score(original,machine_translated):\r\n",
        "    '''\r\n",
        "    Bleu score function given a orginal and a machine translated sentences\r\n",
        "    '''\r\n",
        "    mt_length = len(machine_translated.split())\r\n",
        "    o_length = len(original.split())\r\n",
        "\r\n",
        "    # Brevity Penalty \r\n",
        "    if mt_length>o_length:\r\n",
        "        BP=1\r\n",
        "    else:\r\n",
        "        penality=1-(mt_length/o_length)\r\n",
        "        BP=np.exp(penality)\r\n",
        "\r\n",
        "    # Clipped precision\r\n",
        "    clipped_precision_score = []\r\n",
        "    for i in range(1, 5):\r\n",
        "        original_n_gram = Counter(n_gram_generator(original,i))\r\n",
        "        machine_n_gram = Counter(n_gram_generator(machine_translated,i))\r\n",
        "\r\n",
        "        c = sum(machine_n_gram.values())\r\n",
        "        for j in machine_n_gram:\r\n",
        "            if j in original_n_gram:\r\n",
        "                if machine_n_gram[j] > original_n_gram[j]:\r\n",
        "                    machine_n_gram[j] = original_n_gram[j]\r\n",
        "            else:\r\n",
        "                machine_n_gram[j] = 0\r\n",
        "\r\n",
        "        #print (sum(machine_n_gram.values()), c)\r\n",
        "        clipped_precision_score.append(sum(machine_n_gram.values())/c)\r\n",
        "\r\n",
        "    #print (clipped_precision_score)\r\n",
        "\r\n",
        "    weights =[0.25]*4\r\n",
        "\r\n",
        "    s = (w_i * math.log(p_i) for w_i, p_i in zip(weights, clipped_precision_score))\r\n",
        "    s = BP * math.exp(math.fsum(s))\r\n",
        "    return s\r\n",
        "\r\n",
        "original = \"It is a guide to action which ensures that the military alwasy obeys the command of the party\"\r\n",
        "machine_translated = \"It is the guiding principle which guarantees the military forces alwasy being under the command of the party\"\r\n",
        "\r\n",
        "print (bleu_score(original, machine_translated))\r\n",
        "print (sentence_bleu([original.split()], machine_translated.split()))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.27098211583470044\n",
            "0.27098211583470044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phlyxMnm-Tpx"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(\n",
        "    name='train_accuracy')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeHumfr7zmMa"
      },
      "source": [
        "## Training and checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiysUa--4tOU"
      },
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOJUSB1T8GjM"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by \n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzuf06YZp66w"
      },
      "source": [
        "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNhuYfllndLZ"
      },
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/VinBigData/checkpoints/train121\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKpoA6q1sJFj"
      },
      "source": [
        "EPOCHS = 0"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWZIMEVZ8eTl"
      },
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths o4/1AY0e-g5NwERYfvXHd5gYJ0PO1FU94gGYrmyMq14BU0Dlvo5oiSqu1suLElor variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "# @tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  # print('inner train')\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  \n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    # print('---------------------------------')\n",
        "    predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "  train_loss(loss)\n",
        "  # print('--------------------')\n",
        "  # print(accuracy_function(tar_real, predictions))\n",
        "  # print('--------------------')\n",
        "  train_accuracy(accuracy_function(tar_real, predictions))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H315b1hp8e9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ecdfe42-60c9-40aa-bf1b-288a0d507116"
      },
      "source": [
        "EPOCHS = 100\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  # inp -> en, tar -> vn\n",
        "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "    train_step(inp, tar)\n",
        "    \n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "      \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "    \n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 8.6418 Accuracy 0.0004\n",
            "Epoch 1 Batch 50 Loss 8.5565 Accuracy 0.0264\n",
            "Epoch 1 Batch 100 Loss 8.3731 Accuracy 0.1076\n",
            "Epoch 1 Loss 8.3359 Accuracy 0.1194\n",
            "Time taken for 1 epoch: 71.75035333633423 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 8.2982 Accuracy 0.0558\n",
            "Epoch 2 Batch 50 Loss 8.0836 Accuracy 0.0844\n",
            "Epoch 2 Batch 100 Loss 7.8751 Accuracy 0.1379\n",
            "Epoch 2 Loss 7.8344 Accuracy 0.1466\n",
            "Time taken for 1 epoch: 58.7335205078125 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 7.6899 Accuracy 0.0446\n",
            "Epoch 3 Batch 50 Loss 7.3761 Accuracy 0.0845\n",
            "Epoch 3 Batch 100 Loss 7.1972 Accuracy 0.1374\n",
            "Epoch 3 Loss 7.1603 Accuracy 0.1464\n",
            "Time taken for 1 epoch: 58.84591603279114 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 6.9187 Accuracy 0.0477\n",
            "Epoch 4 Batch 50 Loss 6.6558 Accuracy 0.0847\n",
            "Epoch 4 Batch 100 Loss 6.5870 Accuracy 0.1376\n",
            "Epoch 4 Loss 6.5656 Accuracy 0.1469\n",
            "Time taken for 1 epoch: 57.39196062088013 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 6.4074 Accuracy 0.0540\n",
            "Epoch 5 Batch 50 Loss 6.2054 Accuracy 0.0876\n",
            "Epoch 5 Batch 100 Loss 6.1937 Accuracy 0.1421\n",
            "Saving checkpoint for epoch 5 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-1\n",
            "Epoch 5 Loss 6.1739 Accuracy 0.1512\n",
            "Time taken for 1 epoch: 59.495580196380615 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 6.0812 Accuracy 0.0828\n",
            "Epoch 6 Batch 50 Loss 5.8527 Accuracy 0.1387\n",
            "Epoch 6 Batch 100 Loss 5.8436 Accuracy 0.1770\n",
            "Epoch 6 Loss 5.8303 Accuracy 0.1831\n",
            "Time taken for 1 epoch: 56.554795265197754 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 5.8944 Accuracy 0.1123\n",
            "Epoch 7 Batch 50 Loss 5.5554 Accuracy 0.1707\n",
            "Epoch 7 Batch 100 Loss 5.5444 Accuracy 0.1999\n",
            "Epoch 7 Loss 5.5342 Accuracy 0.2046\n",
            "Time taken for 1 epoch: 56.49505281448364 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 5.6484 Accuracy 0.1335\n",
            "Epoch 8 Batch 50 Loss 5.2606 Accuracy 0.1982\n",
            "Epoch 8 Batch 100 Loss 5.2879 Accuracy 0.2187\n",
            "Epoch 8 Loss 5.2878 Accuracy 0.2224\n",
            "Time taken for 1 epoch: 58.23139142990112 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 5.3178 Accuracy 0.1608\n",
            "Epoch 9 Batch 50 Loss 4.9934 Accuracy 0.2237\n",
            "Epoch 9 Batch 100 Loss 5.0470 Accuracy 0.2384\n",
            "Epoch 9 Loss 5.0439 Accuracy 0.2421\n",
            "Time taken for 1 epoch: 55.618245124816895 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 4.9221 Accuracy 0.1965\n",
            "Epoch 10 Batch 50 Loss 4.7612 Accuracy 0.2451\n",
            "Epoch 10 Batch 100 Loss 4.8304 Accuracy 0.2576\n",
            "Saving checkpoint for epoch 10 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-2\n",
            "Epoch 10 Loss 4.8322 Accuracy 0.2609\n",
            "Time taken for 1 epoch: 55.91564750671387 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 4.6072 Accuracy 0.2379\n",
            "Epoch 11 Batch 50 Loss 4.5096 Accuracy 0.2708\n",
            "Epoch 11 Batch 100 Loss 4.5953 Accuracy 0.2796\n",
            "Epoch 11 Loss 4.5966 Accuracy 0.2825\n",
            "Time taken for 1 epoch: 57.629781007766724 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 4.7400 Accuracy 0.2144\n",
            "Epoch 12 Batch 50 Loss 4.2936 Accuracy 0.2936\n",
            "Epoch 12 Batch 100 Loss 4.3639 Accuracy 0.3022\n",
            "Epoch 12 Loss 4.3600 Accuracy 0.3049\n",
            "Time taken for 1 epoch: 56.66357159614563 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 4.3981 Accuracy 0.2571\n",
            "Epoch 13 Batch 50 Loss 4.0779 Accuracy 0.3161\n",
            "Epoch 13 Batch 100 Loss 4.1288 Accuracy 0.3249\n",
            "Epoch 13 Loss 4.1272 Accuracy 0.3274\n",
            "Time taken for 1 epoch: 56.348230838775635 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 4.2743 Accuracy 0.2781\n",
            "Epoch 14 Batch 50 Loss 3.8557 Accuracy 0.3414\n",
            "Epoch 14 Batch 100 Loss 3.9071 Accuracy 0.3471\n",
            "Epoch 14 Loss 3.9048 Accuracy 0.3502\n",
            "Time taken for 1 epoch: 58.82121515274048 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 3.8939 Accuracy 0.3095\n",
            "Epoch 15 Batch 50 Loss 3.6750 Accuracy 0.3597\n",
            "Epoch 15 Batch 100 Loss 3.6770 Accuracy 0.3734\n",
            "Saving checkpoint for epoch 15 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-3\n",
            "Epoch 15 Loss 3.6677 Accuracy 0.3766\n",
            "Time taken for 1 epoch: 57.48461961746216 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 3.4915 Accuracy 0.3673\n",
            "Epoch 16 Batch 50 Loss 3.4786 Accuracy 0.3852\n",
            "Epoch 16 Batch 100 Loss 3.4490 Accuracy 0.4009\n",
            "Epoch 16 Loss 3.4415 Accuracy 0.4034\n",
            "Time taken for 1 epoch: 57.763843297958374 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 3.6788 Accuracy 0.3386\n",
            "Epoch 17 Batch 50 Loss 3.2967 Accuracy 0.4051\n",
            "Epoch 17 Batch 100 Loss 3.2228 Accuracy 0.4265\n",
            "Epoch 17 Loss 3.2103 Accuracy 0.4297\n",
            "Time taken for 1 epoch: 55.33600187301636 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 3.7158 Accuracy 0.3287\n",
            "Epoch 18 Batch 50 Loss 3.1271 Accuracy 0.4267\n",
            "Epoch 18 Batch 100 Loss 3.0315 Accuracy 0.4503\n",
            "Epoch 18 Loss 3.0121 Accuracy 0.4547\n",
            "Time taken for 1 epoch: 57.06226062774658 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 3.2104 Accuracy 0.3955\n",
            "Epoch 19 Batch 50 Loss 2.9537 Accuracy 0.4476\n",
            "Epoch 19 Batch 100 Loss 2.8182 Accuracy 0.4775\n",
            "Epoch 19 Loss 2.8016 Accuracy 0.4815\n",
            "Time taken for 1 epoch: 58.886234521865845 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 3.1031 Accuracy 0.4039\n",
            "Epoch 20 Batch 50 Loss 2.8081 Accuracy 0.4675\n",
            "Epoch 20 Batch 100 Loss 2.6356 Accuracy 0.5023\n",
            "Saving checkpoint for epoch 20 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-4\n",
            "Epoch 20 Loss 2.6098 Accuracy 0.5066\n",
            "Time taken for 1 epoch: 59.30006790161133 secs\n",
            "\n",
            "Epoch 21 Batch 0 Loss 3.1775 Accuracy 0.4072\n",
            "Epoch 21 Batch 50 Loss 2.6560 Accuracy 0.4856\n",
            "Epoch 21 Batch 100 Loss 2.4649 Accuracy 0.5239\n",
            "Epoch 21 Loss 2.4340 Accuracy 0.5301\n",
            "Time taken for 1 epoch: 59.39899492263794 secs\n",
            "\n",
            "Epoch 22 Batch 0 Loss 2.9619 Accuracy 0.4284\n",
            "Epoch 22 Batch 50 Loss 2.5119 Accuracy 0.5053\n",
            "Epoch 22 Batch 100 Loss 2.2649 Accuracy 0.5527\n",
            "Epoch 22 Loss 2.2402 Accuracy 0.5581\n",
            "Time taken for 1 epoch: 58.9233820438385 secs\n",
            "\n",
            "Epoch 23 Batch 0 Loss 3.0299 Accuracy 0.4041\n",
            "Epoch 23 Batch 50 Loss 2.3880 Accuracy 0.5205\n",
            "Epoch 23 Batch 100 Loss 2.1261 Accuracy 0.5722\n",
            "Epoch 23 Loss 2.0916 Accuracy 0.5784\n",
            "Time taken for 1 epoch: 58.8304603099823 secs\n",
            "\n",
            "Epoch 24 Batch 0 Loss 2.5870 Accuracy 0.4668\n",
            "Epoch 24 Batch 50 Loss 2.2604 Accuracy 0.5397\n",
            "Epoch 24 Batch 100 Loss 1.9810 Accuracy 0.5935\n",
            "Epoch 24 Loss 1.9452 Accuracy 0.6003\n",
            "Time taken for 1 epoch: 58.070578813552856 secs\n",
            "\n",
            "Epoch 25 Batch 0 Loss 2.7055 Accuracy 0.4635\n",
            "Epoch 25 Batch 50 Loss 2.1407 Accuracy 0.5555\n",
            "Epoch 25 Batch 100 Loss 1.8318 Accuracy 0.6146\n",
            "Saving checkpoint for epoch 25 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-5\n",
            "Epoch 25 Loss 1.7967 Accuracy 0.6206\n",
            "Time taken for 1 epoch: 58.32475519180298 secs\n",
            "\n",
            "Epoch 26 Batch 0 Loss 2.7001 Accuracy 0.4491\n",
            "Epoch 26 Batch 50 Loss 2.0272 Accuracy 0.5733\n",
            "Epoch 26 Batch 100 Loss 1.6939 Accuracy 0.6369\n",
            "Epoch 26 Loss 1.6599 Accuracy 0.6430\n",
            "Time taken for 1 epoch: 57.60151433944702 secs\n",
            "\n",
            "Epoch 27 Batch 0 Loss 2.6630 Accuracy 0.4521\n",
            "Epoch 27 Batch 50 Loss 1.8974 Accuracy 0.5941\n",
            "Epoch 27 Batch 100 Loss 1.5893 Accuracy 0.6534\n",
            "Epoch 27 Loss 1.5556 Accuracy 0.6589\n",
            "Time taken for 1 epoch: 58.598886489868164 secs\n",
            "\n",
            "Epoch 28 Batch 0 Loss 2.4865 Accuracy 0.4811\n",
            "Epoch 28 Batch 50 Loss 1.7729 Accuracy 0.6159\n",
            "Epoch 28 Batch 100 Loss 1.4560 Accuracy 0.6777\n",
            "Epoch 28 Loss 1.4240 Accuracy 0.6833\n",
            "Time taken for 1 epoch: 58.25617432594299 secs\n",
            "\n",
            "Epoch 29 Batch 0 Loss 2.5545 Accuracy 0.4755\n",
            "Epoch 29 Batch 50 Loss 1.7035 Accuracy 0.6272\n",
            "Epoch 29 Batch 100 Loss 1.3736 Accuracy 0.6907\n",
            "Epoch 29 Loss 1.3415 Accuracy 0.6965\n",
            "Time taken for 1 epoch: 57.86698031425476 secs\n",
            "\n",
            "Epoch 30 Batch 0 Loss 2.5455 Accuracy 0.4764\n",
            "Epoch 30 Batch 50 Loss 1.5784 Accuracy 0.6471\n",
            "Epoch 30 Batch 100 Loss 1.2871 Accuracy 0.7053\n",
            "Saving checkpoint for epoch 30 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-6\n",
            "Epoch 30 Loss 1.2586 Accuracy 0.7104\n",
            "Time taken for 1 epoch: 56.900513648986816 secs\n",
            "\n",
            "Epoch 31 Batch 0 Loss 2.3939 Accuracy 0.4803\n",
            "Epoch 31 Batch 50 Loss 1.5213 Accuracy 0.6557\n",
            "Epoch 31 Batch 100 Loss 1.2164 Accuracy 0.7181\n",
            "Epoch 31 Loss 1.1919 Accuracy 0.7229\n",
            "Time taken for 1 epoch: 57.620776891708374 secs\n",
            "\n",
            "Epoch 32 Batch 0 Loss 2.3123 Accuracy 0.5178\n",
            "Epoch 32 Batch 50 Loss 1.4768 Accuracy 0.6614\n",
            "Epoch 32 Batch 100 Loss 1.1612 Accuracy 0.7267\n",
            "Epoch 32 Loss 1.1348 Accuracy 0.7320\n",
            "Time taken for 1 epoch: 58.07350540161133 secs\n",
            "\n",
            "Epoch 33 Batch 0 Loss 2.4845 Accuracy 0.4656\n",
            "Epoch 33 Batch 50 Loss 1.3949 Accuracy 0.6759\n",
            "Epoch 33 Batch 100 Loss 1.0992 Accuracy 0.7372\n",
            "Epoch 33 Loss 1.0823 Accuracy 0.7404\n",
            "Time taken for 1 epoch: 58.38310980796814 secs\n",
            "\n",
            "Epoch 34 Batch 0 Loss 2.2305 Accuracy 0.5028\n",
            "Epoch 34 Batch 50 Loss 1.3225 Accuracy 0.6882\n",
            "Epoch 34 Batch 100 Loss 1.0477 Accuracy 0.7466\n",
            "Epoch 34 Loss 1.0366 Accuracy 0.7481\n",
            "Time taken for 1 epoch: 58.740561962127686 secs\n",
            "\n",
            "Epoch 35 Batch 0 Loss 2.1535 Accuracy 0.5071\n",
            "Epoch 35 Batch 50 Loss 1.2729 Accuracy 0.6971\n",
            "Epoch 35 Batch 100 Loss 0.9923 Accuracy 0.7572\n",
            "Saving checkpoint for epoch 35 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-7\n",
            "Epoch 35 Loss 0.9764 Accuracy 0.7597\n",
            "Time taken for 1 epoch: 58.73663830757141 secs\n",
            "\n",
            "Epoch 36 Batch 0 Loss 1.7372 Accuracy 0.5965\n",
            "Epoch 36 Batch 50 Loss 1.1965 Accuracy 0.7123\n",
            "Epoch 36 Batch 100 Loss 0.9527 Accuracy 0.7646\n",
            "Epoch 36 Loss 0.9376 Accuracy 0.7673\n",
            "Time taken for 1 epoch: 57.987950801849365 secs\n",
            "\n",
            "Epoch 37 Batch 0 Loss 2.0009 Accuracy 0.5444\n",
            "Epoch 37 Batch 50 Loss 1.1578 Accuracy 0.7196\n",
            "Epoch 37 Batch 100 Loss 0.9194 Accuracy 0.7709\n",
            "Epoch 37 Loss 0.9036 Accuracy 0.7740\n",
            "Time taken for 1 epoch: 58.15264010429382 secs\n",
            "\n",
            "Epoch 38 Batch 0 Loss 1.7000 Accuracy 0.6004\n",
            "Epoch 38 Batch 50 Loss 1.1194 Accuracy 0.7248\n",
            "Epoch 38 Batch 100 Loss 0.8837 Accuracy 0.7778\n",
            "Epoch 38 Loss 0.8684 Accuracy 0.7808\n",
            "Time taken for 1 epoch: 59.264092445373535 secs\n",
            "\n",
            "Epoch 39 Batch 0 Loss 1.9050 Accuracy 0.5708\n",
            "Epoch 39 Batch 50 Loss 1.0385 Accuracy 0.7414\n",
            "Epoch 39 Batch 100 Loss 0.8144 Accuracy 0.7907\n",
            "Epoch 39 Loss 0.8032 Accuracy 0.7935\n",
            "Time taken for 1 epoch: 56.229506731033325 secs\n",
            "\n",
            "Epoch 40 Batch 0 Loss 1.6287 Accuracy 0.6123\n",
            "Epoch 40 Batch 50 Loss 0.9977 Accuracy 0.7509\n",
            "Epoch 40 Batch 100 Loss 0.7794 Accuracy 0.8001\n",
            "Saving checkpoint for epoch 40 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-8\n",
            "Epoch 40 Loss 0.7750 Accuracy 0.8013\n",
            "Time taken for 1 epoch: 59.70072102546692 secs\n",
            "\n",
            "Epoch 41 Batch 0 Loss 1.5413 Accuracy 0.6285\n",
            "Epoch 41 Batch 50 Loss 0.9353 Accuracy 0.7640\n",
            "Epoch 41 Batch 100 Loss 0.7326 Accuracy 0.8101\n",
            "Epoch 41 Loss 0.7304 Accuracy 0.8112\n",
            "Time taken for 1 epoch: 59.93215084075928 secs\n",
            "\n",
            "Epoch 42 Batch 0 Loss 1.5111 Accuracy 0.6285\n",
            "Epoch 42 Batch 50 Loss 0.8654 Accuracy 0.7768\n",
            "Epoch 42 Batch 100 Loss 0.6860 Accuracy 0.8191\n",
            "Epoch 42 Loss 0.6780 Accuracy 0.8209\n",
            "Time taken for 1 epoch: 59.20734238624573 secs\n",
            "\n",
            "Epoch 43 Batch 0 Loss 1.3475 Accuracy 0.6603\n",
            "Epoch 43 Batch 50 Loss 0.8286 Accuracy 0.7836\n",
            "Epoch 43 Batch 100 Loss 0.6477 Accuracy 0.8279\n",
            "Epoch 43 Loss 0.6408 Accuracy 0.8296\n",
            "Time taken for 1 epoch: 58.56514811515808 secs\n",
            "\n",
            "Epoch 44 Batch 0 Loss 1.3771 Accuracy 0.6541\n",
            "Epoch 44 Batch 50 Loss 0.7909 Accuracy 0.7915\n",
            "Epoch 44 Batch 100 Loss 0.6220 Accuracy 0.8342\n",
            "Epoch 44 Loss 0.6168 Accuracy 0.8353\n",
            "Time taken for 1 epoch: 59.97502541542053 secs\n",
            "\n",
            "Epoch 45 Batch 0 Loss 1.2212 Accuracy 0.6943\n",
            "Epoch 45 Batch 50 Loss 0.7304 Accuracy 0.8051\n",
            "Epoch 45 Batch 100 Loss 0.5948 Accuracy 0.8401\n",
            "Saving checkpoint for epoch 45 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-9\n",
            "Epoch 45 Loss 0.5918 Accuracy 0.8410\n",
            "Time taken for 1 epoch: 58.74186730384827 secs\n",
            "\n",
            "Epoch 46 Batch 0 Loss 1.3689 Accuracy 0.6546\n",
            "Epoch 46 Batch 50 Loss 0.7157 Accuracy 0.8074\n",
            "Epoch 46 Batch 100 Loss 0.5726 Accuracy 0.8444\n",
            "Epoch 46 Loss 0.5680 Accuracy 0.8458\n",
            "Time taken for 1 epoch: 59.66138768196106 secs\n",
            "\n",
            "Epoch 47 Batch 0 Loss 1.1122 Accuracy 0.7078\n",
            "Epoch 47 Batch 50 Loss 0.6686 Accuracy 0.8195\n",
            "Epoch 47 Batch 100 Loss 0.5265 Accuracy 0.8571\n",
            "Epoch 47 Loss 0.5252 Accuracy 0.8577\n",
            "Time taken for 1 epoch: 56.853914976119995 secs\n",
            "\n",
            "Epoch 48 Batch 0 Loss 1.0262 Accuracy 0.7193\n",
            "Epoch 48 Batch 50 Loss 0.6339 Accuracy 0.8257\n",
            "Epoch 48 Batch 100 Loss 0.5052 Accuracy 0.8598\n",
            "Epoch 48 Loss 0.5045 Accuracy 0.8601\n",
            "Time taken for 1 epoch: 57.20243048667908 secs\n",
            "\n",
            "Epoch 49 Batch 0 Loss 1.2584 Accuracy 0.6734\n",
            "Epoch 49 Batch 50 Loss 0.6127 Accuracy 0.8324\n",
            "Epoch 49 Batch 100 Loss 0.5027 Accuracy 0.8606\n",
            "Epoch 49 Loss 0.5017 Accuracy 0.8617\n",
            "Time taken for 1 epoch: 58.224016427993774 secs\n",
            "\n",
            "Epoch 50 Batch 0 Loss 1.0849 Accuracy 0.7216\n",
            "Epoch 50 Batch 50 Loss 0.5870 Accuracy 0.8378\n",
            "Epoch 50 Batch 100 Loss 0.4742 Accuracy 0.8680\n",
            "Saving checkpoint for epoch 50 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-10\n",
            "Epoch 50 Loss 0.4739 Accuracy 0.8689\n",
            "Time taken for 1 epoch: 57.558947801589966 secs\n",
            "\n",
            "Epoch 51 Batch 0 Loss 0.9805 Accuracy 0.7227\n",
            "Epoch 51 Batch 50 Loss 0.5471 Accuracy 0.8451\n",
            "Epoch 51 Batch 100 Loss 0.4521 Accuracy 0.8725\n",
            "Epoch 51 Loss 0.4532 Accuracy 0.8730\n",
            "Time taken for 1 epoch: 58.08142566680908 secs\n",
            "\n",
            "Epoch 52 Batch 0 Loss 1.0632 Accuracy 0.7208\n",
            "Epoch 52 Batch 50 Loss 0.5209 Accuracy 0.8550\n",
            "Epoch 52 Batch 100 Loss 0.4288 Accuracy 0.8798\n",
            "Epoch 52 Loss 0.4338 Accuracy 0.8791\n",
            "Time taken for 1 epoch: 57.263240814208984 secs\n",
            "\n",
            "Epoch 53 Batch 0 Loss 1.0508 Accuracy 0.7167\n",
            "Epoch 53 Batch 50 Loss 0.5004 Accuracy 0.8593\n",
            "Epoch 53 Batch 100 Loss 0.4145 Accuracy 0.8835\n",
            "Epoch 53 Loss 0.4207 Accuracy 0.8823\n",
            "Time taken for 1 epoch: 56.77001667022705 secs\n",
            "\n",
            "Epoch 54 Batch 0 Loss 0.8848 Accuracy 0.7515\n",
            "Epoch 54 Batch 50 Loss 0.4777 Accuracy 0.8638\n",
            "Epoch 54 Batch 100 Loss 0.3943 Accuracy 0.8879\n",
            "Epoch 54 Loss 0.4007 Accuracy 0.8869\n",
            "Time taken for 1 epoch: 56.900012254714966 secs\n",
            "\n",
            "Epoch 55 Batch 0 Loss 0.8108 Accuracy 0.7710\n",
            "Epoch 55 Batch 50 Loss 0.4587 Accuracy 0.8699\n",
            "Epoch 55 Batch 100 Loss 0.3857 Accuracy 0.8908\n",
            "Saving checkpoint for epoch 55 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-11\n",
            "Epoch 55 Loss 0.3886 Accuracy 0.8903\n",
            "Time taken for 1 epoch: 57.90175914764404 secs\n",
            "\n",
            "Epoch 56 Batch 0 Loss 0.7725 Accuracy 0.7806\n",
            "Epoch 56 Batch 50 Loss 0.4497 Accuracy 0.8713\n",
            "Epoch 56 Batch 100 Loss 0.3808 Accuracy 0.8917\n",
            "Epoch 56 Loss 0.3828 Accuracy 0.8910\n",
            "Time taken for 1 epoch: 57.4892098903656 secs\n",
            "\n",
            "Epoch 57 Batch 0 Loss 0.6682 Accuracy 0.8089\n",
            "Epoch 57 Batch 50 Loss 0.4336 Accuracy 0.8744\n",
            "Epoch 57 Batch 100 Loss 0.3630 Accuracy 0.8953\n",
            "Epoch 57 Loss 0.3680 Accuracy 0.8945\n",
            "Time taken for 1 epoch: 57.04270148277283 secs\n",
            "\n",
            "Epoch 58 Batch 0 Loss 0.7765 Accuracy 0.7757\n",
            "Epoch 58 Batch 50 Loss 0.4082 Accuracy 0.8813\n",
            "Epoch 58 Batch 100 Loss 0.3508 Accuracy 0.8988\n",
            "Epoch 58 Loss 0.3575 Accuracy 0.8975\n",
            "Time taken for 1 epoch: 57.16912317276001 secs\n",
            "\n",
            "Epoch 59 Batch 0 Loss 0.7742 Accuracy 0.7795\n",
            "Epoch 59 Batch 50 Loss 0.3986 Accuracy 0.8849\n",
            "Epoch 59 Batch 100 Loss 0.3398 Accuracy 0.9022\n",
            "Epoch 59 Loss 0.3474 Accuracy 0.9007\n",
            "Time taken for 1 epoch: 59.37846541404724 secs\n",
            "\n",
            "Epoch 60 Batch 0 Loss 0.6041 Accuracy 0.8362\n",
            "Epoch 60 Batch 50 Loss 0.3836 Accuracy 0.8888\n",
            "Epoch 60 Batch 100 Loss 0.3236 Accuracy 0.9069\n",
            "Saving checkpoint for epoch 60 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-12\n",
            "Epoch 60 Loss 0.3318 Accuracy 0.9048\n",
            "Time taken for 1 epoch: 57.559375047683716 secs\n",
            "\n",
            "Epoch 61 Batch 0 Loss 0.6885 Accuracy 0.7992\n",
            "Epoch 61 Batch 50 Loss 0.3722 Accuracy 0.8924\n",
            "Epoch 61 Batch 100 Loss 0.3267 Accuracy 0.9062\n",
            "Epoch 61 Loss 0.3307 Accuracy 0.9054\n",
            "Time taken for 1 epoch: 57.658329010009766 secs\n",
            "\n",
            "Epoch 62 Batch 0 Loss 0.7849 Accuracy 0.7850\n",
            "Epoch 62 Batch 50 Loss 0.3648 Accuracy 0.8948\n",
            "Epoch 62 Batch 100 Loss 0.3181 Accuracy 0.9088\n",
            "Epoch 62 Loss 0.3245 Accuracy 0.9075\n",
            "Time taken for 1 epoch: 58.759390354156494 secs\n",
            "\n",
            "Epoch 63 Batch 0 Loss 0.5832 Accuracy 0.8340\n",
            "Epoch 63 Batch 50 Loss 0.3477 Accuracy 0.8982\n",
            "Epoch 63 Batch 100 Loss 0.3039 Accuracy 0.9124\n",
            "Epoch 63 Loss 0.3096 Accuracy 0.9116\n",
            "Time taken for 1 epoch: 58.03404951095581 secs\n",
            "\n",
            "Epoch 64 Batch 0 Loss 0.5931 Accuracy 0.8292\n",
            "Epoch 64 Batch 50 Loss 0.3402 Accuracy 0.9002\n",
            "Epoch 64 Batch 100 Loss 0.3032 Accuracy 0.9120\n",
            "Epoch 64 Loss 0.3095 Accuracy 0.9107\n",
            "Time taken for 1 epoch: 60.0236394405365 secs\n",
            "\n",
            "Epoch 65 Batch 0 Loss 0.4898 Accuracy 0.8522\n",
            "Epoch 65 Batch 50 Loss 0.3245 Accuracy 0.9050\n",
            "Epoch 65 Batch 100 Loss 0.2855 Accuracy 0.9167\n",
            "Saving checkpoint for epoch 65 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-13\n",
            "Epoch 65 Loss 0.2914 Accuracy 0.9158\n",
            "Time taken for 1 epoch: 57.68392896652222 secs\n",
            "\n",
            "Epoch 66 Batch 0 Loss 0.6397 Accuracy 0.8068\n",
            "Epoch 66 Batch 50 Loss 0.3116 Accuracy 0.9080\n",
            "Epoch 66 Batch 100 Loss 0.2802 Accuracy 0.9184\n",
            "Epoch 66 Loss 0.2872 Accuracy 0.9171\n",
            "Time taken for 1 epoch: 57.1826753616333 secs\n",
            "\n",
            "Epoch 67 Batch 0 Loss 0.5427 Accuracy 0.8350\n",
            "Epoch 67 Batch 50 Loss 0.2989 Accuracy 0.9123\n",
            "Epoch 67 Batch 100 Loss 0.2730 Accuracy 0.9212\n",
            "Epoch 67 Loss 0.2797 Accuracy 0.9199\n",
            "Time taken for 1 epoch: 58.281068563461304 secs\n",
            "\n",
            "Epoch 68 Batch 0 Loss 0.5873 Accuracy 0.8305\n",
            "Epoch 68 Batch 50 Loss 0.2959 Accuracy 0.9124\n",
            "Epoch 68 Batch 100 Loss 0.2673 Accuracy 0.9225\n",
            "Epoch 68 Loss 0.2730 Accuracy 0.9211\n",
            "Time taken for 1 epoch: 57.326128005981445 secs\n",
            "\n",
            "Epoch 69 Batch 0 Loss 0.6089 Accuracy 0.8154\n",
            "Epoch 69 Batch 50 Loss 0.2831 Accuracy 0.9170\n",
            "Epoch 69 Batch 100 Loss 0.2601 Accuracy 0.9244\n",
            "Epoch 69 Loss 0.2698 Accuracy 0.9218\n",
            "Time taken for 1 epoch: 57.62757468223572 secs\n",
            "\n",
            "Epoch 70 Batch 0 Loss 0.4316 Accuracy 0.8752\n",
            "Epoch 70 Batch 50 Loss 0.2707 Accuracy 0.9201\n",
            "Epoch 70 Batch 100 Loss 0.2489 Accuracy 0.9271\n",
            "Saving checkpoint for epoch 70 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-14\n",
            "Epoch 70 Loss 0.2546 Accuracy 0.9257\n",
            "Time taken for 1 epoch: 57.50378108024597 secs\n",
            "\n",
            "Epoch 71 Batch 0 Loss 0.5236 Accuracy 0.8472\n",
            "Epoch 71 Batch 50 Loss 0.2631 Accuracy 0.9227\n",
            "Epoch 71 Batch 100 Loss 0.2431 Accuracy 0.9291\n",
            "Epoch 71 Loss 0.2522 Accuracy 0.9271\n",
            "Time taken for 1 epoch: 57.69157290458679 secs\n",
            "\n",
            "Epoch 72 Batch 0 Loss 0.5172 Accuracy 0.8495\n",
            "Epoch 72 Batch 50 Loss 0.2638 Accuracy 0.9214\n",
            "Epoch 72 Batch 100 Loss 0.2412 Accuracy 0.9286\n",
            "Epoch 72 Loss 0.2488 Accuracy 0.9270\n",
            "Time taken for 1 epoch: 57.2490291595459 secs\n",
            "\n",
            "Epoch 73 Batch 0 Loss 0.4610 Accuracy 0.8627\n",
            "Epoch 73 Batch 50 Loss 0.2574 Accuracy 0.9240\n",
            "Epoch 73 Batch 100 Loss 0.2371 Accuracy 0.9301\n",
            "Epoch 73 Loss 0.2458 Accuracy 0.9280\n",
            "Time taken for 1 epoch: 58.54959177970886 secs\n",
            "\n",
            "Epoch 74 Batch 0 Loss 0.4686 Accuracy 0.8605\n",
            "Epoch 74 Batch 50 Loss 0.2505 Accuracy 0.9266\n",
            "Epoch 74 Batch 100 Loss 0.2295 Accuracy 0.9326\n",
            "Epoch 74 Loss 0.2357 Accuracy 0.9308\n",
            "Time taken for 1 epoch: 56.52726650238037 secs\n",
            "\n",
            "Epoch 75 Batch 0 Loss 0.5145 Accuracy 0.8543\n",
            "Epoch 75 Batch 50 Loss 0.2473 Accuracy 0.9266\n",
            "Epoch 75 Batch 100 Loss 0.2268 Accuracy 0.9333\n",
            "Saving checkpoint for epoch 75 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-15\n",
            "Epoch 75 Loss 0.2368 Accuracy 0.9309\n",
            "Time taken for 1 epoch: 59.53583550453186 secs\n",
            "\n",
            "Epoch 76 Batch 0 Loss 0.4334 Accuracy 0.8708\n",
            "Epoch 76 Batch 50 Loss 0.2335 Accuracy 0.9312\n",
            "Epoch 76 Batch 100 Loss 0.2226 Accuracy 0.9346\n",
            "Epoch 76 Loss 0.2314 Accuracy 0.9327\n",
            "Time taken for 1 epoch: 56.819931745529175 secs\n",
            "\n",
            "Epoch 77 Batch 0 Loss 0.4501 Accuracy 0.8624\n",
            "Epoch 77 Batch 50 Loss 0.2298 Accuracy 0.9324\n",
            "Epoch 77 Batch 100 Loss 0.2128 Accuracy 0.9368\n",
            "Epoch 77 Loss 0.2224 Accuracy 0.9346\n",
            "Time taken for 1 epoch: 58.40294909477234 secs\n",
            "\n",
            "Epoch 78 Batch 0 Loss 0.4763 Accuracy 0.8550\n",
            "Epoch 78 Batch 50 Loss 0.2309 Accuracy 0.9318\n",
            "Epoch 78 Batch 100 Loss 0.2181 Accuracy 0.9358\n",
            "Epoch 78 Loss 0.2278 Accuracy 0.9332\n",
            "Time taken for 1 epoch: 58.51673913002014 secs\n",
            "\n",
            "Epoch 79 Batch 0 Loss 0.3854 Accuracy 0.8878\n",
            "Epoch 79 Batch 50 Loss 0.2215 Accuracy 0.9343\n",
            "Epoch 79 Batch 100 Loss 0.2097 Accuracy 0.9379\n",
            "Epoch 79 Loss 0.2191 Accuracy 0.9355\n",
            "Time taken for 1 epoch: 59.13240051269531 secs\n",
            "\n",
            "Epoch 80 Batch 0 Loss 0.3993 Accuracy 0.8769\n",
            "Epoch 80 Batch 50 Loss 0.2141 Accuracy 0.9361\n",
            "Epoch 80 Batch 100 Loss 0.2080 Accuracy 0.9381\n",
            "Saving checkpoint for epoch 80 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-16\n",
            "Epoch 80 Loss 0.2150 Accuracy 0.9364\n",
            "Time taken for 1 epoch: 59.4952757358551 secs\n",
            "\n",
            "Epoch 81 Batch 0 Loss 0.3957 Accuracy 0.8852\n",
            "Epoch 81 Batch 50 Loss 0.2139 Accuracy 0.9361\n",
            "Epoch 81 Batch 100 Loss 0.2038 Accuracy 0.9397\n",
            "Epoch 81 Loss 0.2138 Accuracy 0.9373\n",
            "Time taken for 1 epoch: 57.875577211380005 secs\n",
            "\n",
            "Epoch 82 Batch 0 Loss 0.3207 Accuracy 0.9067\n",
            "Epoch 82 Batch 50 Loss 0.2063 Accuracy 0.9391\n",
            "Epoch 82 Batch 100 Loss 0.2000 Accuracy 0.9407\n",
            "Epoch 82 Loss 0.2085 Accuracy 0.9384\n",
            "Time taken for 1 epoch: 56.5693244934082 secs\n",
            "\n",
            "Epoch 83 Batch 0 Loss 0.3827 Accuracy 0.8862\n",
            "Epoch 83 Batch 50 Loss 0.2033 Accuracy 0.9390\n",
            "Epoch 83 Batch 100 Loss 0.1965 Accuracy 0.9412\n",
            "Epoch 83 Loss 0.2044 Accuracy 0.9393\n",
            "Time taken for 1 epoch: 57.304463624954224 secs\n",
            "\n",
            "Epoch 84 Batch 0 Loss 0.4586 Accuracy 0.8600\n",
            "Epoch 84 Batch 50 Loss 0.2072 Accuracy 0.9379\n",
            "Epoch 84 Batch 100 Loss 0.1974 Accuracy 0.9405\n",
            "Epoch 84 Loss 0.2069 Accuracy 0.9380\n",
            "Time taken for 1 epoch: 59.32907509803772 secs\n",
            "\n",
            "Epoch 85 Batch 0 Loss 0.3466 Accuracy 0.8951\n",
            "Epoch 85 Batch 50 Loss 0.1990 Accuracy 0.9408\n",
            "Epoch 85 Batch 100 Loss 0.1914 Accuracy 0.9425\n",
            "Saving checkpoint for epoch 85 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-17\n",
            "Epoch 85 Loss 0.1991 Accuracy 0.9405\n",
            "Time taken for 1 epoch: 57.90643620491028 secs\n",
            "\n",
            "Epoch 86 Batch 0 Loss 0.3547 Accuracy 0.8939\n",
            "Epoch 86 Batch 50 Loss 0.1860 Accuracy 0.9456\n",
            "Epoch 86 Batch 100 Loss 0.1835 Accuracy 0.9459\n",
            "Epoch 86 Loss 0.1922 Accuracy 0.9434\n",
            "Time taken for 1 epoch: 57.883368253707886 secs\n",
            "\n",
            "Epoch 87 Batch 0 Loss 0.2989 Accuracy 0.9090\n",
            "Epoch 87 Batch 50 Loss 0.1874 Accuracy 0.9445\n",
            "Epoch 87 Batch 100 Loss 0.1824 Accuracy 0.9458\n",
            "Epoch 87 Loss 0.1918 Accuracy 0.9429\n",
            "Time taken for 1 epoch: 58.99875235557556 secs\n",
            "\n",
            "Epoch 88 Batch 0 Loss 0.3539 Accuracy 0.8977\n",
            "Epoch 88 Batch 50 Loss 0.1848 Accuracy 0.9456\n",
            "Epoch 88 Batch 100 Loss 0.1825 Accuracy 0.9448\n",
            "Epoch 88 Loss 0.1898 Accuracy 0.9426\n",
            "Time taken for 1 epoch: 57.333027839660645 secs\n",
            "\n",
            "Epoch 89 Batch 0 Loss 0.3111 Accuracy 0.9062\n",
            "Epoch 89 Batch 50 Loss 0.1800 Accuracy 0.9465\n",
            "Epoch 89 Batch 100 Loss 0.1744 Accuracy 0.9475\n",
            "Epoch 89 Loss 0.1844 Accuracy 0.9448\n",
            "Time taken for 1 epoch: 57.072834968566895 secs\n",
            "\n",
            "Epoch 90 Batch 0 Loss 0.3257 Accuracy 0.9063\n",
            "Epoch 90 Batch 50 Loss 0.1771 Accuracy 0.9467\n",
            "Epoch 90 Batch 100 Loss 0.1726 Accuracy 0.9475\n",
            "Saving checkpoint for epoch 90 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-18\n",
            "Epoch 90 Loss 0.1807 Accuracy 0.9451\n",
            "Time taken for 1 epoch: 57.82156825065613 secs\n",
            "\n",
            "Epoch 91 Batch 0 Loss 0.3493 Accuracy 0.9028\n",
            "Epoch 91 Batch 50 Loss 0.1750 Accuracy 0.9477\n",
            "Epoch 91 Batch 100 Loss 0.1746 Accuracy 0.9469\n",
            "Epoch 91 Loss 0.1846 Accuracy 0.9442\n",
            "Time taken for 1 epoch: 59.12128472328186 secs\n",
            "\n",
            "Epoch 92 Batch 0 Loss 0.3209 Accuracy 0.9139\n",
            "Epoch 92 Batch 50 Loss 0.1733 Accuracy 0.9495\n",
            "Epoch 92 Batch 100 Loss 0.1736 Accuracy 0.9486\n",
            "Epoch 92 Loss 0.1815 Accuracy 0.9464\n",
            "Time taken for 1 epoch: 56.79079270362854 secs\n",
            "\n",
            "Epoch 93 Batch 0 Loss 0.2836 Accuracy 0.9160\n",
            "Epoch 93 Batch 50 Loss 0.1726 Accuracy 0.9486\n",
            "Epoch 93 Batch 100 Loss 0.1666 Accuracy 0.9497\n",
            "Epoch 93 Loss 0.1733 Accuracy 0.9477\n",
            "Time taken for 1 epoch: 56.21043634414673 secs\n",
            "\n",
            "Epoch 94 Batch 0 Loss 0.3023 Accuracy 0.9104\n",
            "Epoch 94 Batch 50 Loss 0.1614 Accuracy 0.9525\n",
            "Epoch 94 Batch 100 Loss 0.1660 Accuracy 0.9498\n",
            "Epoch 94 Loss 0.1743 Accuracy 0.9473\n",
            "Time taken for 1 epoch: 57.397276878356934 secs\n",
            "\n",
            "Epoch 95 Batch 0 Loss 0.3009 Accuracy 0.9119\n",
            "Epoch 95 Batch 50 Loss 0.1593 Accuracy 0.9525\n",
            "Epoch 95 Batch 100 Loss 0.1625 Accuracy 0.9510\n",
            "Saving checkpoint for epoch 95 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-19\n",
            "Epoch 95 Loss 0.1706 Accuracy 0.9485\n",
            "Time taken for 1 epoch: 57.52586364746094 secs\n",
            "\n",
            "Epoch 96 Batch 0 Loss 0.3337 Accuracy 0.9026\n",
            "Epoch 96 Batch 50 Loss 0.1535 Accuracy 0.9544\n",
            "Epoch 96 Batch 100 Loss 0.1581 Accuracy 0.9528\n",
            "Epoch 96 Loss 0.1673 Accuracy 0.9501\n",
            "Time taken for 1 epoch: 55.261441707611084 secs\n",
            "\n",
            "Epoch 97 Batch 0 Loss 0.3145 Accuracy 0.9056\n",
            "Epoch 97 Batch 50 Loss 0.1611 Accuracy 0.9522\n",
            "Epoch 97 Batch 100 Loss 0.1623 Accuracy 0.9511\n",
            "Epoch 97 Loss 0.1698 Accuracy 0.9486\n",
            "Time taken for 1 epoch: 57.28820323944092 secs\n",
            "\n",
            "Epoch 98 Batch 0 Loss 0.2592 Accuracy 0.9258\n",
            "Epoch 98 Batch 50 Loss 0.1529 Accuracy 0.9545\n",
            "Epoch 98 Batch 100 Loss 0.1570 Accuracy 0.9522\n",
            "Epoch 98 Loss 0.1656 Accuracy 0.9498\n",
            "Time taken for 1 epoch: 57.90829014778137 secs\n",
            "\n",
            "Epoch 99 Batch 0 Loss 0.2902 Accuracy 0.9125\n",
            "Epoch 99 Batch 50 Loss 0.1470 Accuracy 0.9560\n",
            "Epoch 99 Batch 100 Loss 0.1519 Accuracy 0.9534\n",
            "Epoch 99 Loss 0.1611 Accuracy 0.9509\n",
            "Time taken for 1 epoch: 55.36761450767517 secs\n",
            "\n",
            "Epoch 100 Batch 0 Loss 0.2788 Accuracy 0.9208\n",
            "Epoch 100 Batch 50 Loss 0.1550 Accuracy 0.9541\n",
            "Epoch 100 Batch 100 Loss 0.1565 Accuracy 0.9527\n",
            "Saving checkpoint for epoch 100 at /content/drive/MyDrive/VinBigData/checkpoints/train121/ckpt-20\n",
            "Epoch 100 Loss 0.1665 Accuracy 0.9499\n",
            "Time taken for 1 epoch: 57.59908437728882 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPtAZFLpkw8z"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfcsSWswSdGV"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5buvMlnvyrFm"
      },
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "def evaluate(inp_sentence):\n",
        "  start_token = [tokenizer_en.vocab_size]\n",
        "  end_token = [tokenizer_en.vocab_size + 1]\n",
        "  \n",
        "  # inp sentence is eng, hence adding the start and end token\n",
        "  inp_sentence = start_token + tokenizer_en.encode(inp_sentence) + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "  \n",
        "  # as the target is vn, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "  decoder_input = [tokenizer_vn.vocab_size]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "  \n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "  \n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    \n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == tokenizer_vn.vocab_size+1:\n",
        "      \n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "      \n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0), attention_weights"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU2_yG_vBGza"
      },
      "source": [
        "def translate(sentence, plot=''):\n",
        "  sentence = preproces_cn(sentence)\n",
        "  result, attention_weights = evaluate(sentence)\n",
        "  predicted_sentence = tokenizer_vn.decode([i for i in result \n",
        "                                            if i < tokenizer_vn.vocab_size])  \n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Predicted translation: {}'.format(predicted_sentence))\n",
        "  return predicted_sentence\n",
        "  if plot:\n",
        "    plot_attention_weights(attention_weights, sentence, result, plot)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-NvetisO_zp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a50127-fc9d-4083-c027-3543a81e44d5"
      },
      "source": [
        "translate('你好！') #chào bạn"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 你 好 ！\n",
            "Predicted translation: chào bạn!\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6HmnIESPepY",
        "outputId": "8a29538d-162b-44c1-af3a-adc02e4f7f3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "translate('好')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 好\n",
            "Predicted translation: tốt\n",
            "tốt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC7btbwOPmer",
        "outputId": "37c0df77-288f-40eb-d7d5-5de1001d8443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "translate('你')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 你\n",
            "Predicted translation: em trai\n",
            "em trai\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KPmiEdURlkv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "41125746-d67c-4267-d311-f1979977002f"
      },
      "source": [
        "translate('我爱你') # anh yêu em"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 我 爱 你\n",
            "Predicted translation: anh yêu em\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'anh yêu em'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Tf8u0lPvBv",
        "outputId": "66915581-39c0-4a8c-9079-02a5752669a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('我') # tôi"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 我\n",
            "Predicted translation: tôi\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tôi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogD4b1MFPyts",
        "outputId": "307c0f9c-8ad5-4db0-8f91-ebc225ba5d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('爱') #yêu"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 爱\n",
            "Predicted translation: yêu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'yêu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSfDYE7vP2UB",
        "outputId": "45fc9292-50af-4fbc-e146-57c59a04d1d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('你') # bạn (ni)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 你\n",
            "Predicted translation: em trai\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'em trai'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HCTD2pkP6rH",
        "outputId": "799ee6a0-a20f-4e87-9c56-30e1d6ecd3de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('我爱') # tôi yêu"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 我 爱\n",
            "Predicted translation: tôi yêu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tôi yêu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfNAR57YP9Fq",
        "outputId": "09fc0036-e84e-4b27-c04f-ab83f4c3ba14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('爱你') # yêu em"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 爱 你\n",
            "Predicted translation: yêu em\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'yêu em'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBqE3S9yPapg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3be827-1b5e-419c-f6b9-368191c8ddb5"
      },
      "source": [
        "print(translate('听说越南的杂技很有意思，我还没看过呢。'))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 听 说 越 南 的 杂 技 很 有 意 思 ， 我 还 没 看 过 呢 。\n",
            "Predicted translation: nghe nói xiếc của việt nam rất thú vị, tôi vẫn chưa xem qua.\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1JClUjSPynI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b987608-1e0e-4726-cde6-a9a818a94ec0"
      },
      "source": [
        "print(translate('你来过越南吗？你来越南以后去过什么地方？'))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 你 来 过 越 南 吗 ？ 你 来 越 南 以 后 去 过 什 么 地 方 ？\n",
            "Predicted translation: bạn đã từng tới việt nam chưa? sau khi bạn tới việt nam đã từng đến nơi nào?\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0mV1V2YQA1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f821b3-2548-4615-9a5e-4a075f22a409"
      },
      "source": [
        "print(translate('我是越南人')) # tôi là người VN"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 我 是 越 南 人\n",
            "Predicted translation: tôi là người việt nam\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ptRunaQQBtF",
        "outputId": "efe5f01d-686c-4b36-c17f-a4d566c94a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('越南人') # người VN"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 越 南 人\n",
            "Predicted translation: người việt nam\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'người việt nam'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCoNoONdQQ4L",
        "outputId": "4bbe672b-e983-48d7-fdc9-2f0e3b35430b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('越南') # VN"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 越 南\n",
            "Predicted translation: việt nam\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'việt nam'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl2oEy-zQU3Z",
        "outputId": "91fe1525-23e8-4e6c-9aaf-3ce133c034e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('人') # người"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 人\n",
            "Predicted translation: người ta\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'người ta'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_be6EgBDQbyJ",
        "outputId": "14428923-4e8c-44d6-c2c6-87ffc38917f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('是越南人') # là người VN"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 是 越 南 人\n",
            "Predicted translation: người việt nam\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'người việt nam'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeV9sLi8T2Qy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "423f831a-11e5-41af-8aa4-f73cafc3796f"
      },
      "source": [
        "print(translate('我不是越南人')) # tôi không là người VN"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 我 不 是 越 南 人\n",
            "Predicted translation: tôi không phải là người việt nam\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuLevzyESCef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129182c7-1170-414c-d97d-30656b251bc5"
      },
      "source": [
        "print(translate('我是中国人')) # anh ta là người Trung Quốc"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 我 是 中 国 人\n",
            "Predicted translation: tôi là người nước ngoài\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfVgv9kHQsHU",
        "outputId": "525dc663-b662-47cd-8f4a-e137d71fae8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('中国人') # Người TQ"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 中 国 人\n",
            "Predicted translation: người trung quốc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'người trung quốc'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8sDnitXQykk",
        "outputId": "c7c2b2f5-837a-428a-dcad-2a8c08b17419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('中国') # TQ"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 中 国\n",
            "Predicted translation: trung quốc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'trung quốc'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMPoGxdQQKiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208bb2d8-3078-4f6c-ad82-40c3211b1bca"
      },
      "source": [
        "print(translate('越南北部的中国')) # Trung Quốc ở phía bắc Việt Nam"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 越 南 北 部 的 中 国\n",
            "Predicted translation: bộ đội việt nam ở trung quốc\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zbGb506PIN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb92e85-fb8a-4563-f978-5154348696c7"
      },
      "source": [
        "print(translate('明天我哥哥很忙。'))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 明 天 我 哥 哥 很 忙 。\n",
            "Predicted translation: ngày mai anh trai tôi rất bận.\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHQuNXaQRPfh",
        "outputId": "f5ea6754-74e6-450c-da58-c46e0d4ed44b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('明天')  # ngày mai"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 明 天\n",
            "Predicted translation: ngày mai\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ngày mai'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR1gg17uRT3U",
        "outputId": "3220aa9d-441d-44c7-87cf-b77dc0bc806d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('我哥哥很忙。') #anh trai tôi rất bận"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 我 哥 哥 很 忙 。\n",
            "Predicted translation: anh trai tôi rất bận.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'anh trai tôi rất bận.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vect-uIgRbQw",
        "outputId": "299a0372-191c-4030-9e1b-6ffd135ef2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('我哥哥') # anh trai tôi"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 哥 哥\n",
            "Predicted translation: anh trai\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'anh trai'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HteMhpVURfBm",
        "outputId": "7397918c-dcd4-444f-f6c8-daa9f40dd584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('很忙。') # rất bận"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 很 忙\n",
            "Predicted translation: rất bận\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'rất bận'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsxrAlvFG8SZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad9f460-5ef9-4d14-abf6-d88c3980f1bd"
      },
      "source": [
        "print(translate('那是英文杂志。'))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 那 是 英 文 杂 志 。\n",
            "Predicted translation: kia là tạp chí tiếng anh?\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dSHKHzYRyto",
        "outputId": "f88dbc40-2566-448c-99aa-48779743554b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('那是英文杂志。')"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 那 是\n",
            "Predicted translation: như thế\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'như thế'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK7g3qnxR-V2",
        "outputId": "2cac7cf0-166f-48bf-ff3d-911dad60682f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('英') # tieengs Anh"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 英\n",
            "Predicted translation: email\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'email'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRk2-_hASIRx",
        "outputId": "68883553-0961-4c06-89d5-4817b041f15d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('杂志。') # tạp chí"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 杂 志 。\n",
            "Predicted translation: tạp chí.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tạp chí.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yCFEY9ESOcO",
        "outputId": "0fa00a6d-fd9c-444d-d688-49b6d4e4d1f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('那是英文') # đó là Tiếng Anh"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 那 是 英 文\n",
            "Predicted translation: kia là tạp chí đó\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'kia là tạp chí đó'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeBxy7LySoUp",
        "outputId": "79311805-e41c-4b89-87ee-1ffaa92c5767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "translate('今天我的工作不太忙。') #Hôm nay công việc của tôi không quá bận."
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 今 天 我 的 工 作 不 太 忙 。\n",
            "Predicted translation: hôm nay công việc của tôi không bận lắm.\n",
            "hôm nay công việc của tôi không bận lắm.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9TeVwhSvPt",
        "outputId": "63ab36e2-39f7-454e-90cc-684b9934d112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('今天') # ngày nay, hiện tại"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 今 天\n",
            "Predicted translation: hiện tại\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hiện tại'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2d4rFZuS05R",
        "outputId": "92920cf2-9418-47c9-80eb-7879f07b0abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('工作') # công việc"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 工 作\n",
            "Predicted translation: công việc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'công việc'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17bo_1vWTAUE",
        "outputId": "b77a56ec-eb85-4527-8a92-d837f379394c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('不太忙。') # không quá bận"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 不 太 忙 。\n",
            "Predicted translation: không bận lắm.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'không bận lắm.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCCI6dfHTGAp",
        "outputId": "e321e923-95f8-444b-e3e6-6513cc386234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('工作不太忙。') # công việc không quá bận"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 工 作 不 太 忙 。\n",
            "Predicted translation: việc của công binh không bận lắm.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'việc của công binh không bận lắm.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bJ2S0x4TNMV",
        "outputId": "563c30bc-6387-4bee-ee85-43468c1196f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('拼命在脑海中寻你') #Khao khát tìm kiếm bạn trong tâm trí của tôi"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 拼 命 在 脑 海 中 寻 你\n",
            "Predicted translation: bất chấp tất cả tìm hình bóng anh trong trí nhớ\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bất chấp tất cả tìm hình bóng anh trong trí nhớ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJmrUlydTVQN",
        "outputId": "202264cd-b297-41e7-89fe-f9b0127a94c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('拼命在') # tuyệt vọng"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 拼 命 在\n",
            "Predicted translation: bất chấp là\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bất chấp là'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPux5SdZTgHe",
        "outputId": "56db6c11-6b16-4c8d-c0a6-fd99dbbac1d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('默守着那个秘密') # âm thầm giữ kín bí mật"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 默 守 着 那 个 秘 密\n",
            "Predicted translation: âm thầm giữ kín bí mật\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'âm thầm giữ kín bí mật'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5VoGwZPT1d_",
        "outputId": "3ea4d3e6-a7cd-4c11-f2bb-3d1c804161d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('默守着那') # giữ im lặng"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 默 守 着 那\n",
            "Predicted translation: âm thầm giữ kín bí mật\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'âm thầm giữ kín bí mật'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfAdutaXT_Ht",
        "outputId": "2bde8139-2cf2-4330-aba0-35c563457a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('个秘密') # bí mật"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 个 秘 密\n",
            "Predicted translation: bí mật\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bí mật'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPpcL8-zUJ3q",
        "outputId": "d1c2bd67-f9b6-4280-ec77-2cde4ee6fd91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('请把飞机票和护照给我看一下儿。') #hãy đưa vé máy bay và hộ chiếu cho tôi xem một chút."
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 请 把 飞 机 票 和 护 照 给 我 看 一 下 儿 。\n",
            "Predicted translation: hãy đưa vé máy bay và hộ chiếu cho tôi xem một chút.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hãy đưa vé máy bay và hộ chiếu cho tôi xem một chút.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PO4yjXOURAA",
        "outputId": "a3eac0f3-07b4-4011-cdcb-4a4621717196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('请给我机票') #Làm ơn cho tôi vé"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 请 给 我 机 票\n",
            "Predicted translation: vé máy đóng bản thân\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'vé máy đóng bản thân'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8eJK-8LUZON",
        "outputId": "2949b942-02a7-45e1-9729-018572d5617a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('机票') # vé máy bay"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 机 票\n",
            "Predicted translation: vé máy bay\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'vé máy bay'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS3iLb_oUbWk",
        "outputId": "6608ab4d-e15d-4f2e-da2d-854ad69d1114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('护照') # hộ chiếu"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 护 照\n",
            "Predicted translation: hộ chiếu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hộ chiếu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ulu32PgUVhyQ",
        "outputId": "1e092291-cab7-4094-a566-a9c575670a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('姓名孙利')"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 姓 名 孙 利\n",
            "Predicted translation: cháu gái\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cháu gái'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZO3aAXaVy3q",
        "outputId": "ca812999-2366-48e9-d112-bbfbed10d549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "translate('​​​​​​​性男')"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: ​ ​ ​ ​ ​ ​ ​ 性 男\n",
            "Predicted translation: người đi tàu chạy, duyên hạnh phúc đều tin vào những dây chết và ung dung tự mình và mỗi người và mỗi lần và mỗi lần và mỗi lần và không dám nói, nhưng mà lại dấu vết\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'người đi tàu chạy, duyên hạnh phúc đều tin vào những dây chết và ung dung tự mình và mỗi người và mỗi lần và mỗi lần và mỗi lần và không dám nói, nhưng mà lại dấu vết'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_0KtctDV0Rr",
        "outputId": "5dd7b531-f22a-41d0-ef87-9835d3c103f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('民族汉')"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 民 族 汉\n",
            "Predicted translation: tấm dân tộc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tấm dân tộc'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfTFsDDVV2A2",
        "outputId": "1d97bd28-c7e9-4079-ea23-78c200b2da07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('出生1986年2月1')"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 出 生 1 9 8 6 年 2 月 1\n",
            "Predicted translation: cha năm nay nữ thú nghiệp vụ qua  - tây tạng đến lhasa.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cha năm nay nữ thú nghiệp vụ qua  - tây tạng đến lhasa.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1z_8SuIV3As",
        "outputId": "7f026500-7ab9-4a16-da74-7c1c26f278c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('往姓天津市南开区沱江路沱江')"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 往 姓 天 津 市 南 开 区 沱 江 路 沱 江\n",
            "Predicted translation: họ được người săn  (cần mở hương thơm hải la..)cho phép.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'họ được người săn  (cần mở hương thơm hải la..)cho phép.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtD8yCLsV4QG",
        "outputId": "4a67827c-e0dc-475c-e3f3-fc3499869eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('里11号楼5门2号')"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 里 1 1 号 楼 5 门 2 号\n",
            "Predicted translation: mã nước biển báo trong triết học\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mã nước biển báo trong triết học'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REJi6KPxV5hF",
        "outputId": "e2be6b21-ca19-411b-af81-26d0778311d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "translate('{​​​​​​​公民身份号码')"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: { ​ ​ ​ ​ ​ ​ ​ 公 民 身 份 号 码\n",
            "Predicted translation: một người săn tàu khiển từ đề mà nói: nhất định phải có những việc chăm chỉ, đừng thưởng ngoạn? bởi vì ngay bên cạnh tranh\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'một người săn tàu khiển từ đề mà nói: nhất định phải có những việc chăm chỉ, đừng thưởng ngoạn? bởi vì ngay bên cạnh tranh'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J97QHvtV6gS",
        "outputId": "d0276327-540b-4645-caef-54d76ab8f21f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "translate('120104198602014333')"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 1 2 0 1 0 4 1 9 8 6 0 2 0 1 4 3 3 3\n",
            "Predicted translation: mùa xanh là gọi là chín kém, lập dự trữ vào say tiếng anh\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mùa xanh là gọi là chín kém, lập dự trữ vào say tiếng anh'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACerpPvQUfsK",
        "outputId": "a44b33df-2d8e-438f-9635-460624fc258f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "translate('如果事与愿违，就相信上天一定另有安排，所有失去的，都会以另外一种方式归来。相信自己，相信时间不会亏带你。')"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 如 果 事 与 愿 违 ， 就 相 信 上 天 一 定 另 有 安 排 ， 所 有 失 去 的 ， 都 会 以 另 外 一 种 方 式 归 来 。 相 信 自 己 ， 相 信 时 间 不 会 亏 带 你 。\n",
            "Predicted translation: nếu những sự việc xảy ra không như những gì bạn mong muốn thì hãy tin tưởng rằng ông trời nhất định đã có sắp xếp khác. tất cả những gì mất đi sẽ tìm lại được bằng một cách khác. tin tưởng vào bản thân và tin tưởng rằng thời gian sẽ không đối xử tệ bạc với tôi.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'nếu những sự việc xảy ra không như những gì bạn mong muốn thì hãy tin tưởng rằng ông trời nhất định đã có sắp xếp khác. tất cả những gì mất đi sẽ tìm lại được bằng một cách khác. tin tưởng vào bản thân và tin tưởng rằng thời gian sẽ không đối xử tệ bạc với tôi.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7x7m65BOcMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16aa652-f79c-4e0d-cde9-4681a85c70fd"
      },
      "source": [
        "print(translate('明天下了课我就去办公室找她。'))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 明 天 下 了 课 我 就 去 办 公 室 找 她 。\n",
            "Predicted translation: ngày mai ăn cơm xong tôi sẽ đến tìm cô ta.\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSlVcHVBfh-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d113be-9371-4dfb-8275-42817020b67d"
      },
      "source": [
        "print(translate('真正的失败从来都不是结果的不仅如人意，而是拥有的时候随意挥霍，和未曾用心尝试前的轻言放弃。'))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 真 正 的 失 败 从 来 都 不 是 结 果 的 不 仅 如 人 意 ， 而 是 拥 有 的 时 候 随 意 挥 霍 ， 和 未 曾 用 心 尝 试 前 的 轻 言 放 弃 。\n",
            "Predicted translation: thất bại thật sự không phải là kết quả không được như ý muốn mà là khi ta đang nắm giữ trong tay nhưng không biết trân trọng mà lại tùy tiện và dễ dàng từ bỏ khi chưa nếm trải qua hay quyết tâm giữ lấy.\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JQrqaPZO40H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2138ec89-d07f-469b-bd1c-dd18732aa260"
      },
      "source": [
        "print(translate('真正的失败从来都不是结果的不仅如人意，而是拥有的时候随意挥霍，和未曾用心尝试前的轻言放弃。'))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 真 正 的 失 败 从 来 都 不 是 结 果 的 不 仅 如 人 意 ， 而 是 拥 有 的 时 候 随 意 挥 霍 ， 和 未 曾 用 心 尝 试 前 的 轻 言 放 弃 。\n",
            "Predicted translation: thất bại thật sự không phải là kết quả không được như ý muốn mà là khi ta đang nắm giữ trong tay nhưng không biết trân trọng mà lại tùy tiện và dễ dàng từ bỏ khi chưa nếm trải qua hay quyết tâm giữ lấy.\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ7zPBmBOQOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e494b82-73ba-4e59-a4ae-493f04e7207e"
      },
      "source": [
        "print(translate('你的名字写下来不过几厘米长，却贯穿了我这么长时光。其实你不知道，你一直是我的梦想。'))\r\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 你 的 名 字 写 下 来 不 过 几 厘 米 长 ， 却 贯 穿 了 我 这 么 长 时 光 。 其 实 你 不 知 道 ， 你 一 直 是 我 的 梦 想 。\n",
            "Predicted translation: tên của anh khi viết xuống giấy trắng quá dài có vài centimét, nhưng lại xuyên suốt cả một quãng thời gian thanh xuân của em. thực ra anh không biết rằng anh không biết rằng anh không biết rằng anh không biết rằng anh chính là ước mơ của em.\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gtzO9ztf-AX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "367409af-f7f2-4004-e84c-111f54be993f"
      },
      "source": [
        "print(translate('写给自己的第二封信 人生，总会有不期而遇的温暖，和生生不息的希望。不管前方的路有多苦，只要走的方向正确，不管多么崎岖不平，都比站在原地更接近幸福。'))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 写 给 自 己 的 第 二 封 信 人 生 ， 总 会 有 不 期 而 遇 的 温 暖 ， 和 生 生 不 息 的 希 望 。 不 管 前 方 的 路 有 多 苦 ， 只 要 走 的 方 向 正 确 ， 不 管 多 么 崎 岖 不 平 ， 都 比 站 在 原 地 更 接 近 幸 福 。\n",
            "Predicted translation: đời người luôn có những điều ấm áp không mong mà tới, và cả những hi vọng không ngừng lớn lên. cho dù con đường phía trước có bao nhiêu khổ ải, chỉ cần hướng đi đúng thì dù trên đường đi đúng thì chỉ cần hướng tầm cao hơn có bao nhiêu chông gai gập ghềnh cũng còn trông xa hơn chỉ có những gì thì chỉ có bao nhiêu, tầm mắt, tầm mắt, mãi ở bên nhau gần nhất. một ngày mai mà thôi.\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPM5cqn6glrZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b494569-8a02-4414-ac05-41c9aa14da1f"
      },
      "source": [
        "print(translate('如果你感到委屈，证明你还有底线；如果你感到迷茫，证明你还有追求；如果你感到痛苦，证明你还有力气；如果你感到绝望，证明你还要希望。 从某种意义上，你永远都不会被打倒，因为你还有你。'))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 如 果 你 感 到 委 屈 ， 证 明 你 还 有 底 线 ； 如 果 你 感 到 迷 茫 ， 证 明 你 还 有 追 求 ； 如 果 你 感 到 痛 苦 ， 证 明 你 还 有 力 气 ； 如 果 你 感 到 绝 望 ， 证 明 你 还 要 希 望 。 从 某 种 意 义 上 ， 你 永 远 都 不 会 被 打 倒 ， 因 为 你 还 有 你 。\n",
            "Predicted translation: nếu như bạn cảm thấy oan ức thì chứng tỏ bạn vẫn còn giới hạn. nếu như bạn cảm thấy mông lung lạc lối chứng tỏ bạn vẫn còn nhiều điều muốn theo đuổi. nếu như bạn cảm thấy đau khổ chứng tỏ bạn vẫn còn sức lực. nếu như bạn cảm thấy tuyệt vọng chứng tỏ bạn vẫn còn hy vọng. trên một tầng ý nghĩa nào đó, bạn vĩnh viễn sẽ không bị bất cứ điều gì đạp đổ bởi vì bạn vẫn còn bản thân mình.\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9enwvl9hFCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a1e866-c67e-4825-931d-8e7950199050"
      },
      "source": [
        "print(translate('今天我的工作不太忙。'))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 今 天 我 的 工 作 不 太 忙 。\n",
            "Predicted translation: hôm nay công việc của tôi không bận lắm.\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epSENeOKKLFy"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlRHgmMeKMuN",
        "outputId": "06226900-88ff-463e-bd1d-867283624adf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "scores = 0 \r\n",
        "num = 50\r\n",
        "for i in range(num):\r\n",
        "  xx = content_vn[i]\r\n",
        "  yy = translate(content_en[i])\r\n",
        "  print(xx)\r\n",
        "  print(yy)\r\n",
        "  score = sentence_bleu([xx.split()], yy.split())\r\n",
        "  print(score)\r\n",
        "  scores += score\r\n",
        "print(scores/num)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 写 给 自 己 的 第 二 封 信 人 生 ， 总 会 有 不 期 而 遇 的 温 暖 ， 和 生 生 不 息 的 希 望 。 不 管 前 方 的 路 有 多 苦 ， 只 要 走 的 方 向 正 确 ， 不 管 多 么 崎 岖 不 平 ， 都 比 站 在 原 地 更 接 近 幸 福 。\n",
            "Predicted translation: đời người luôn có những điều ấm áp không mong mà tới, và cả những hi vọng không ngừng lớn lên. cho dù con đường phía trước có bao nhiêu khổ ải, chỉ cần hướng đi đúng thì dù trên đường đi đúng thì chỉ cần hướng tầm cao hơn có bao nhiêu chông gai gập ghềnh cũng còn trông xa hơn chỉ có những gì thì chỉ có bao nhiêu, tầm mắt, tầm mắt, mãi ở bên nhau gần nhất. một ngày mai mà thôi.\n",
            "đời người luôn có những điều ấm áp không mong mà tới, và cả những hi vọng không ngừng lớn lên. cho dù con đường phía trước có bao nhiêu khổ ải, chỉ cần hướng đi đúng thì dù trên đường đi có bao nhiêu chông gai gập ghềnh cũng còn gần với bến bờ hạnh phúc hơn chỉ đứng mãi ở vạch xuất phát.\n",
            "đời người luôn có những điều ấm áp không mong mà tới, và cả những hi vọng không ngừng lớn lên. cho dù con đường phía trước có bao nhiêu khổ ải, chỉ cần hướng đi đúng thì dù trên đường đi đúng thì chỉ cần hướng tầm cao hơn có bao nhiêu chông gai gập ghềnh cũng còn trông xa hơn chỉ có những gì thì chỉ có bao nhiêu, tầm mắt, tầm mắt, mãi ở bên nhau gần nhất. một ngày mai mà thôi.\n",
            "0.586743726584702\n",
            "Input: 你 是 个 要 强 的 人 ， 时 时 刻 刻 要 求 自 己 做 到 百 分 之 百 的 超 出 期 望 值 。 但 是 苛 求 并 不 是 个 好 现 象 ， 你 并 不 是 天 才 ， 请 允 许 自 己 犯 错 。 不 要 太 着 急 ， 你 的 努 力 ， 时 间 都 会 帮 你 兑 现 。\n",
            "Predicted translation: bạn là một người mạnh mẽ, bất kể lúc nào cũng bắt mình phải làm được trọn vẹn 100% những kì vọng của bản thân. nhưng nghiêm khắc quá cũng không phải là điều tốt, bạn không phải là thiên tài, hãy cho phép mình phạm sai lầm, đừng quá vội vàng, những nỗ lực của bạn, thời gian sẽ giúp bạn thực hiện.\n",
            "bạn là một người mạnh mẽ, bất kể lúc nào cũng bắt mình phải làm được trọn vẹn 100% những kì vọng của bản thân. nhưng nghiêm khắc quá cũng không phải là điều tốt, bạn không phải là thiên tài, hãy cho phép mình phạm sai lầm, đừng quá vội vàng, những nỗ lực của bạn, thời gian sẽ giúp bạn thực hiện.\n",
            "bạn là một người mạnh mẽ, bất kể lúc nào cũng bắt mình phải làm được trọn vẹn 100% những kì vọng của bản thân. nhưng nghiêm khắc quá cũng không phải là điều tốt, bạn không phải là thiên tài, hãy cho phép mình phạm sai lầm, đừng quá vội vàng, những nỗ lực của bạn, thời gian sẽ giúp bạn thực hiện.\n",
            "1.0\n",
            "Input: 写 给 自 己 的 第 四 封 信 时 间 在 变 ， 人 也 在 变 。 生 活 是 一 场 无 法 回 放 的 绝 版 电 影 ， 有 些 事 不 管 你 如 何 努 力 ， 回 不 去 就 是 回 不 去 了 。 世 界 上 最 远 的 距 离 ， 不 是 爱 ， 不 是 恨 ， 而 是 熟 悉 的 人 ， 渐 渐 变 得 陌 生 。\n",
            "Predicted translation: thời gian thay đổi, lòng người cũng thay đổi, cuộc sống của chúng ta tựa như một thứ hai thứ bất cứ trôi đi chẳng còn sợ là ta chẳng mong chờ hết con tiết kiệm, có những gì là nào đi nữa thì không níu giữ lại chẳng còn có gì con đường tới đâu liền phải là chúng ta được như thế giới này con cơ hội trọn vẹn thuộc về phía trước mắt, có những thứ nhất không quan trọng nhưng vẫn có gì con đường phía trước thì vĩnh viễn sẽ chẳng còn đông đã từng đi không làm được như thế nào, có những thứ giống nhau.\n",
            "thời gian thay đổi, lòng người cũng thay đổi, cuộc sống của chúng ta tựa như một bộ phim điện ảnh không chiếu lại thêm lần nào nữa, có những thứ dù cho chúng ta có cố gắng đến như thế nào đi nữa thì cũng chẳng bao giờ trở lại được như xưa. trên đời này cái khoảng cách xa nhất không phải là yêu, chẳng phải là hận, mà là những người quen biết nhau dần trở nên xa lạ với nhau.\n",
            "thời gian thay đổi, lòng người cũng thay đổi, cuộc sống của chúng ta tựa như một thứ hai thứ bất cứ trôi đi chẳng còn sợ là ta chẳng mong chờ hết con tiết kiệm, có những gì là nào đi nữa thì không níu giữ lại chẳng còn có gì con đường tới đâu liền phải là chúng ta được như thế giới này con cơ hội trọn vẹn thuộc về phía trước mắt, có những thứ nhất không quan trọng nhưng vẫn có gì con đường phía trước thì vĩnh viễn sẽ chẳng còn đông đã từng đi không làm được như thế nào, có những thứ giống nhau.\n",
            "0.21335724803340042\n",
            "Input: 写 给 自 己 的 第 五 封 信 很 多 时 候 你 在 奋 力 拼 搏 后 未 能 获 得 你 想 要 的 ， 并 不 是 因 为 你 不 配 ， 而 只 是 时 机 未 到 ， 你 要 做 的 ， 只 是 咬 紧 牙 关 ， 将 如 此 努 力 的 自 己 继 续 保 持 下 去 ， 仅 此 而 已 。\n",
            "Predicted translation: có nhiều lúc bạn đã cố gắng hết sức nhưng vẫn chưa thể có được những gì bạn muốn, không dám quyết định là, không xứng mà chỉ là thời cơ chưa đến, không thể quyết định phải làm chỉ đơn giản là cắn chặt răng, cứ tiếp tục để bạn vẫn cố gắng như thế, chỉ có vậy thôi.\n",
            "có nhiều lúc bạn đã cố gắng hết sức nhưng vẫn chưa thể có được những gì bạn muốn, không phải là vì bạn không xứng mà chỉ là thời cơ chưa đến, những thứ bạn phải làm chỉ đơn giản là cắn chặt răng, cứ tiếp tục để bản thân mình vẫn cố gắng như thế, chỉ có vậy thôi.\n",
            "có nhiều lúc bạn đã cố gắng hết sức nhưng vẫn chưa thể có được những gì bạn muốn, không dám quyết định là, không xứng mà chỉ là thời cơ chưa đến, không thể quyết định phải làm chỉ đơn giản là cắn chặt răng, cứ tiếp tục để bạn vẫn cố gắng như thế, chỉ có vậy thôi.\n",
            "0.7565607331143263\n",
            "Input: 所 谓 奇 迹 ， 大 概 都 是 这 样 吧 - - - - - 奇 迹 并 非 是 上 天 赐 予 某 人 原 本 不 应 获 得 的 东 西 ， 而 是 对 于 勤 奋 者 姗 姗 来 迟 的 褒 奖 ， 它 只 会 迟 到 ， 却 从 不 缺 席 。\n",
            "Predicted translation: cái gọi là kì tích đại khái đều là như thế này, kỳ tích không có nghĩa là những thứ mà thượng đế ban tặng cho ai đó nhẽ ra không đáng được nhận, mà là những giải thưởng được gửi đến từ giành cho những người chăm chỉ, nó chỉ đến muộn chứ không bao giờ vằng mặt.\n",
            "cái gọi là kì tích đại khái đều là như thế này, kỳ tích không có nghĩa là những thứ mà thượng đế ban tặng cho ai đó nhẽ ra không đáng được nhận, mà là những giải thưởng được gửi đến từ từ giành cho những người chăm chỉ, nó chỉ đến muộn chứ không bao giờ vằng mặt.\n",
            "cái gọi là kì tích đại khái đều là như thế này, kỳ tích không có nghĩa là những thứ mà thượng đế ban tặng cho ai đó nhẽ ra không đáng được nhận, mà là những giải thưởng được gửi đến từ giành cho những người chăm chỉ, nó chỉ đến muộn chứ không bao giờ vằng mặt.\n",
            "0.969993452158124\n",
            "Input: 宫 崎 骏 在 他 的 电 影 里 说 ： \" 我 始 终 相 信 ， 在 这 个 世 界 上 ， 一 定 有 另 一 个 自 己 ， 在 做 着 我 不 敢 做 的 事 ， 在 过 着 我 不 敢 过 的 生 活 。 \" 其 实 我 们 每 个 人 都 是 另 一 个 自 己 ， 只 要 我 们 愿 意 ， 就 每 有 我 们 不 敢 做 的 事 ， 没 有 我 们 过 不 上 的 生 活 。\n",
            "Predicted translation: miyazaki hayao đã từng nói thế này trong phim của ông ấy: \"từ trước đến nay tôi đều tin rằng trên đời này có một 'tôi' khác tồn tại, dám làm những thứ tôi không dám làm, dám sống cuộc sống mà tôi không dám sống.\" thực ra thì ai trong chúng ta đều có bản ngã khác của chính mình, chỉ cần chúng ta muốn, chẳng có gì chúng ta không dám làm, chẳng có gì chúng ta không vượt qua chẳng có gì chúng ta cũng không dám làm, chẳng có những gì tôi sống nào không dám làm, chẳng có gì chúng ta mới cố gắng cuộc sống mà không vượt qua chính là những thứ sẽ không dám sống.\n",
            "miyazaki hayao đã từng nói thế này trong phim của ông ấy: \"từ trước đến nay tôi đều tin rằng trên đời này có một 'tôi' khác tồn tại, dám làm những thứ tôi không dám làm, dám sống cuộc sống mà tôi không dám sống.\" thực ra thì ai trong chúng ta đều có bản ngã khác của chính mình, chỉ cần chúng ta muốn, chẳng có gì chúng ta không dám làm, chẳng có cuộc sống nào không vượt qua được.\n",
            "miyazaki hayao đã từng nói thế này trong phim của ông ấy: \"từ trước đến nay tôi đều tin rằng trên đời này có một 'tôi' khác tồn tại, dám làm những thứ tôi không dám làm, dám sống cuộc sống mà tôi không dám sống.\" thực ra thì ai trong chúng ta đều có bản ngã khác của chính mình, chỉ cần chúng ta muốn, chẳng có gì chúng ta không dám làm, chẳng có gì chúng ta không vượt qua chẳng có gì chúng ta cũng không dám làm, chẳng có những gì tôi sống nào không dám làm, chẳng có gì chúng ta mới cố gắng cuộc sống mà không vượt qua chính là những thứ sẽ không dám sống.\n",
            "0.6392962888305148\n",
            "Input: 或 许 你 感 觉 自 己 一 无 所 有 ， 或 许 你 会 羡 慕 上 司 的 房 子 ， 车 子 ， 学 姐 们 的 钻 石 耳 钉 。 其 实 你 不 用 羡 慕 这 些 ， 只 要 努 力 ， 所 有 的 一 切 ， 岁 月 都 会 带 给 你 。 而 你 的 年 轻 岁 月 ， 却 是 他 们 再 也 无 法 拥 有 的 。\n",
            "Predicted translation: có lẽ bạn cảm thấy mình chẳng có gì, cũng có thể bạn sẽ ngưỡng mộ căn trong phạm sai lầm, trong phạm trường đang lâm vào đôi khi ta chẳng còn việc gì. có thể bạn đang giảo biện. một ngày mai muốn về phía trước hay không. một ngày mai thì cũng có thể ung dung không có thể ung dung không có một nhiệm với bạn học cách gì. một nhiệm với cuộc sống mà là thứ nhất của bạn. một ngày bạn nhất của bạn. một người khác mà không đủ tốt đẹp nhất mà, những thứ sẽ không đủ tốt đẹp hơn ôm trong tay. có những thứ luôn có thể mạnh mẽ hơn.\n",
            "có lẽ bạn cảm thấy mình chẳng có gì, cũng có thể bạn sẽ ngưỡng mộ căn nhà rồi cả xe đẹp của cấp trên mình hoặc là đôi khuyên tai kim cương chị bạn trong trường đang đeo. thực ra bạn không cần phải đi ngưỡng mộ những thứ này, chỉ cần bạn nỗ lực, tất cả mọi thứ, thời gian đều mang đến cho bạn. những năm tháng thanh xuân của bạn, lại là thứ học chẳng bao giờ có được.\n",
            "có lẽ bạn cảm thấy mình chẳng có gì, cũng có thể bạn sẽ ngưỡng mộ căn trong phạm sai lầm, trong phạm trường đang lâm vào đôi khi ta chẳng còn việc gì. có thể bạn đang giảo biện. một ngày mai muốn về phía trước hay không. một ngày mai thì cũng có thể ung dung không có thể ung dung không có một nhiệm với bạn học cách gì. một nhiệm với cuộc sống mà là thứ nhất của bạn. một ngày bạn nhất của bạn. một người khác mà không đủ tốt đẹp nhất mà, những thứ sẽ không đủ tốt đẹp hơn ôm trong tay. có những thứ luôn có thể mạnh mẽ hơn.\n",
            "0.16683049946912404\n",
            "Input: 写 给 自 己 的 第 九 封 信 你 现 在 的 结 果 ， 都 是 你 以 前 的 种 种 行 为 造 成 的 。 如 果 你 讨 厌 自 己 的 现 在 ， 更 应 该 反 思 一 下 自 己 。 因 为 每 一 个 你 不 满 意 的 现 在 ， 都 有 一 个 不 努 力 的 曾 经 。\n",
            "Predicted translation: kết quả của bây giờ đều là do những hành động ngày trước tạo nên. nếu bạn ghét mình của hiện tại thì càng nên xem mỗi ngày mai ghét bỏ ra, mỗi điều ở hiện tại mà bạn không hài lòng đều là do có những gì đối mặt của mỗi ngày đều là do dự.\n",
            "kết quả của bây giờ đều là do những hành động ngày trước tạo nên. nếu bạn ghét mình của hiện tại thì càng nên xem lại mình một chút. bởi vì mỗi điều ở hiện tại mà bạn không hài lòng đều là do có những cái trước kia bạn không cố gắng đủ.\n",
            "kết quả của bây giờ đều là do những hành động ngày trước tạo nên. nếu bạn ghét mình của hiện tại thì càng nên xem mỗi ngày mai ghét bỏ ra, mỗi điều ở hiện tại mà bạn không hài lòng đều là do có những gì đối mặt của mỗi ngày đều là do dự.\n",
            "0.6836356861441135\n",
            "Input: 年 轻 正 是 吃 苦 的 时 候 ， 正 是 发 奋 努 力 的 时 候 。 你 一 定 要 相 信 ， 每 一 个 发 奋 努 力 的 背 后 ， 必 有 加 倍 的 奖 赏 。 今 天 的 生 活 是 由 三 年 前 确 定 的 ， 但 是 如 果 你 今 天 还 过 着 和 三 年 前 一 样 的 生 活 ， 那 么 三 年 后 的 你 仍 将 如 此 。\n",
            "Predicted translation: tuổi trẻ chính là lúc nếm trải cực khổ, cũng chính là việc mình muốn mà chúng ta nỗ lực hết đâu. bạn nhất định phải tin rằng đằng sau những sự nỗ lực mà là tiêu bạn nhất định phải là do từng bước sống, nhưng phải sống mà là do bạn đang sống vẫn cố gắng hết sức mạnh mẽ hơn. nhưng vẫn nhất định nỗ lực, thì vĩnh viễn sẽ chẳng còn những gì của năm sau. nhưng vẫn cứ như mà là bị lạc lối tầm nào. có ngày hôm nay bạn sẽ làm tốt thôi.\n",
            "tuổi trẻ chính là lúc nếm trải cực khổ, cũng chính là lúc chúng ta nỗ lực hết mình. bạn nhất định phải tin rằng đằng sau những sự nỗ lực kia là phần thưởng đáng giá hơn gấp bội. cuộc sống của ngày hôm nay là do 3 năm trước quyết định, nhưng nếu hôm nay bạn vẫn sống cuộc sống của 3 năm trước thì bạn của 3 năm sau vẫn cứ như thế mà thôi.\n",
            "tuổi trẻ chính là lúc nếm trải cực khổ, cũng chính là việc mình muốn mà chúng ta nỗ lực hết đâu. bạn nhất định phải tin rằng đằng sau những sự nỗ lực mà là tiêu bạn nhất định phải là do từng bước sống, nhưng phải sống mà là do bạn đang sống vẫn cố gắng hết sức mạnh mẽ hơn. nhưng vẫn nhất định nỗ lực, thì vĩnh viễn sẽ chẳng còn những gì của năm sau. nhưng vẫn cứ như mà là bị lạc lối tầm nào. có ngày hôm nay bạn sẽ làm tốt thôi.\n",
            "0.3050907913230061\n",
            "Input: 写 给 自 己 的 第 十 一 封 信 其 实 奋 斗 就 是 每 天 踏 踏 实 实 地 过 好 日 子 ， 做 好 手 头 的 每 件 小 事 ， 不 拖 拉 ， 不 抱 怨 ， 不 推 卸 ， 不 偷 懒 。 每 一 天 一 点 一 滴 的 努 力 ， 才 能 汇 集 起 千 万 勇 气 ， 带 着 你 的 坚 持 ， 引 领 你 到 你 想 要 到 的 地 方 去 。\n",
            "Predicted translation: thực ra phấn đấu chính là bình thản sống mỗi ngày, làm thật tốt những việc mình đang phải làm, không trì hoãn, không than phiền, không thoái thác, không lười biếng. mỗi ngày cố gắng thêm một chút xíu, mới có thể gộp thành hàng ngàn dũng khí, mang theo sự kiên trì, dẫn bạn đến nơi bạn muốn đến.\n",
            "thực ra phấn đấu chính là bình thản sống mỗi ngày, làm thật tốt những việc mình đang phải làm, không trì hoãn, không than phiền, không thoái thác, không lười biếng. mỗi ngày cố gắng thêm một chút xíu, mới có thể gộp thành hàng ngàn dũng khí, mang theo sự kiên trì, dẫn bạn đến nơi bạn muốn đến.\n",
            "thực ra phấn đấu chính là bình thản sống mỗi ngày, làm thật tốt những việc mình đang phải làm, không trì hoãn, không than phiền, không thoái thác, không lười biếng. mỗi ngày cố gắng thêm một chút xíu, mới có thể gộp thành hàng ngàn dũng khí, mang theo sự kiên trì, dẫn bạn đến nơi bạn muốn đến.\n",
            "1.0\n",
            "Input: 每 一 个 努 力 的 人 都 能 在 岁 月 中 破 茧 成 蝶 ， 你 要 相 信 ， 有 一 天 你 将 破 蛹 而 出 ， 成 长 得 比 人 们 期 待 的 还 要 美 丽 ， 但 这 个 过 程 会 很 痛 ， 会 很 辛 苦 ， 有 时 候 还 会 觉 得 灰 心 。 面 对 着 汹 涌 而 来 的 现 实 ， 觉 得 自 己 渺 小 无 力 ， 但 这 也 是 生 命 的 一 部 分 。 做 好 现 在 你 能 做 的 ， 然 后 ， 一 切 都 会 好 起 来 。\n",
            "Predicted translation: những người biết cố gắng đều sẽ có một ngày từ nhộng hóa thành bướm, bạn phá ra sau đó bạn phá kén chui ra, trở nên xa nhất không ngừng lớn nhất định hôm nay phá sâu vào bản thân sẽ phá kén chui ra, sẽ có ngày mai thì sẽ có ngày mai thì sẽ có lúc còn mọi thứ, trở nên mới xảy ra sẽ tốt đẹp hơn và nỗ lực nhưng vẫn muốn đạt được đắm này. trở nên xa lạ với kỳ vọng thì ra sẽ có những người tầm thường. sẽ trở thành những người tầm thường. sẽ trở nên mới biết được. sau này hoàn hảo nhất mà \"nơi sáng xong thì thôi.\n",
            "những người biết cố gắng đều sẽ có một ngày từ nhộng hóa thành bướm, bạn phải tin rằng, rồi sẽ có ngày bạn phá kén chui ra, trở nên xinh đẹp hơn rất nhiều so với kỳ vọng của mọi người. nhưng quá trình này sẽ rất đau đớn, sẽ rất gian khổ, có lúc còn cảm thấy nản lòng thoái chí. đối mặt với hiện thực dồn đến mãnh liệt, bạn cảm thấy bản thân thật nhỏ bé và yếu đuối. nhưng đây chính là một phần của cuộc sống. hãy làm tốt những điều bây giờ bạn có thể làm, rồi sau đó mọi thứ sẽ tốt lên thôi.\n",
            "những người biết cố gắng đều sẽ có một ngày từ nhộng hóa thành bướm, bạn phá ra sau đó bạn phá kén chui ra, trở nên xa nhất không ngừng lớn nhất định hôm nay phá sâu vào bản thân sẽ phá kén chui ra, sẽ có ngày mai thì sẽ có ngày mai thì sẽ có lúc còn mọi thứ, trở nên mới xảy ra sẽ tốt đẹp hơn và nỗ lực nhưng vẫn muốn đạt được đắm này. trở nên xa lạ với kỳ vọng thì ra sẽ có những người tầm thường. sẽ trở thành những người tầm thường. sẽ trở nên mới biết được. sau này hoàn hảo nhất mà \"nơi sáng xong thì thôi.\n",
            "0.23169055233714927\n",
            "Input: 每 个 成 功 的 人 在 成 功 之 前 ， 难 免 都 会 有 一 段 黯 淡 的 时 光 。 此 时 ， 你 无 须 害 怕 ， 也 无 须 胆 怯 ， 只 需 努 力 朝 着 自 己 的 目 标 大 步 迈 进 ， 然 后 再 付 出 强 于 以 往 三 倍 的 努 力 ， 若 干 年 后 ， 你 一 定 会 超 越 现 在 的 自 己 。\n",
            "Predicted translation: mỗi một người thành đạt trước khi tiến tới thành công, đều khó tránh khỏi trải qua khoảng thời gian tối tăm ảm đạm. những lúc như vậy, bạn không muốn lựa chọn của một lần sự cố gắng trở nên kiên trì luyện từng bước về phía trước. nhiều lúc xong những lúc chúng ta đã từng bỏ ra, thì mơ mới không nên không vượt qua chỉ muốn ra. nhiều năm sau, bạn nhất định nhất định sẽ không không chịu thua cả.\n",
            "mỗi một người thành đạt trước khi tiến tới thành công, đều khó tránh khỏi trải qua khoảng thời gian tối tăm ảm đạm. những lúc như vậy, bạn không cần sợ hãi, cũng đừng nhút nhát, chỉ cần cố gắng tiến từng bước về phía mục tiêu của bạn, sau đó tiếp tục cố gắng hơn gấp ba lần sự cố gắng bạn đã từng bỏ ra. nhiều năm sau, bạn nhất định sẽ vượt qua chính bản thân của hiện tại.\n",
            "mỗi một người thành đạt trước khi tiến tới thành công, đều khó tránh khỏi trải qua khoảng thời gian tối tăm ảm đạm. những lúc như vậy, bạn không muốn lựa chọn của một lần sự cố gắng trở nên kiên trì luyện từng bước về phía trước. nhiều lúc xong những lúc chúng ta đã từng bỏ ra, thì mơ mới không nên không vượt qua chỉ muốn ra. nhiều năm sau, bạn nhất định nhất định sẽ không không chịu thua cả.\n",
            "0.5013248048593126\n",
            "Input: 每 一 个 优 秀 的 人 ， 都 会 有 一 段 沉 默 的 时 光 ， 不 抱 怨 、 不 责 难 ， 不 断 努 力 ， 忍 受 着 黑 夜 的 孤 独 与 寂 寞 ， 坚 信 在 黑 暗 中 也 能 盛 开 出 最 好 的 花 。\n",
            "Predicted translation: mỗi người tài giỏi đều có một thời gian trầm lặng, họ không than phiền hay trách móc, mà họ không ngừng nỗ lực, nhẫn nhịn chịu đựng những đêm dài cô độc và trống vắng, mang theo niềm tin rằng tại nơi tối tăm ảm đạm vẫn có thể nở ra đóa hoa xinh đẹp nhất.\n",
            "mỗi người tài giỏi đều có một khoảng thời gian trầm lặng, họ không than phiền hay trách móc, mà họ không ngừng nỗ lực, nhẫn nhịn chịu đựng những đêm dài cô độc và trống vắng, mang theo niềm tin rằng tại nơi tối tăm ảm đạm vẫn có thể nở ra đóa hoa xinh đẹp nhất.\n",
            "mỗi người tài giỏi đều có một thời gian trầm lặng, họ không than phiền hay trách móc, mà họ không ngừng nỗ lực, nhẫn nhịn chịu đựng những đêm dài cô độc và trống vắng, mang theo niềm tin rằng tại nơi tối tăm ảm đạm vẫn có thể nở ra đóa hoa xinh đẹp nhất.\n",
            "0.9554255769940484\n",
            "Input: 你 现 在 还 很 年 轻 ， 完 全 没 有 必 要 因 为 你 的 衣 服 不 如 别 人 ， 包 不 是 名 牌 ， 或 者 存 款 还 不 到 五 位 数 而 觉 得 不 安 。 因 为 每 一 个 人 都 是 这 样 过 来 的 ， 你 自 己 才 是 一 切 的 根 源 ， 要 想 改 变 人 生 ， 首 先 要 改 变 自 己 ！\n",
            "Predicted translation: bây giờ bạn vẫn còn rất trẻ, hoàn toàn không cần buồn bực chỉ vì quần áo, túi xách của mình không phải hàng hiệu giống người ta, hoặc tiền tiết kiệm chưa được đến năm con số như người ta. bởi vì ai ai cũng đều tiến lên như vậy, chính bản thân bạn mới là căn nguyên của tất cả, muốn đổi đời trước hết phải thay đổi chính mình.\n",
            "bây giờ bạn vẫn còn rất trẻ, hoàn toàn không cần buồn bực chỉ vì quần áo, túi xách của mình không phải hàng hiệu giống người ta, hoặc tiền tiết kiệm chưa được đến năm con số như người ta. bởi vì ai ai cũng đều tiến lên như vậy, chính bản thân bạn mới là căn nguyên của tất cả, muốn đổi đời trước hết phải thay đổi chính mình.\n",
            "bây giờ bạn vẫn còn rất trẻ, hoàn toàn không cần buồn bực chỉ vì quần áo, túi xách của mình không phải hàng hiệu giống người ta, hoặc tiền tiết kiệm chưa được đến năm con số như người ta. bởi vì ai ai cũng đều tiến lên như vậy, chính bản thân bạn mới là căn nguyên của tất cả, muốn đổi đời trước hết phải thay đổi chính mình.\n",
            "1.0\n",
            "Input: 纵 使 你 天 生 就 拿 到 一 副 好 牌 ， 也 不 能 保 证 你 人 生 的 棋 局 会 步 步 顺 畅 ， 也 未 必 能 保 证 你 在 生 活 的 博 弈 中 稳 操 胜 券 。 好 的 人 生 棋 局 ， 要 靠 自 己 步 步 为 营 ， 努 力 去 争 取 。\n",
            "Predicted translation: cho dù bạn trời sinh đang lãng quên được người khác nhất định phải cố gắng sẽ được gọi là lãng phí, để hành động quan trọng. điều có thể đón nhận được đắm trong ánh sáng sớm bảo hiểm trở nên mạnh mẽ hơn, nếu có thể đón nhận ra khỏi cửa hàng hào quang mang xe, mong muốn.\n",
            "cho dù bạn trời sinh đã được ban cho một ván cờ đẹp, cũng không thể chắc chắn rằng ván cờ cuộc đời bạn sẽ được đầu xuôi đuôi lọt, cũng chưa chắc bảo đảm được rằng mọi nước cờ bạn đi sẽ nắm chắc phần thắng. để có một ván cờ cuộc đời tốt đẹp, bạn phải dựa vào bản thân mình, thận trọng trong từng bước đi và tranh thủ mọi cơ hội.\n",
            "cho dù bạn trời sinh đang lãng quên được người khác nhất định phải cố gắng sẽ được gọi là lãng phí, để hành động quan trọng. điều có thể đón nhận được đắm trong ánh sáng sớm bảo hiểm trở nên mạnh mẽ hơn, nếu có thể đón nhận ra khỏi cửa hàng hào quang mang xe, mong muốn.\n",
            "0.061327177898017685\n",
            "Input: 所 有 的 成 功 ， 都 来 自 于 不 倦 的 努 力 和 奔 跑 ； 所 有 幸 福 ， 都 来 自 平 凡 的 奋 斗 和 坚 持 ， 你 无 法 找 到 捷 径 。\n",
            "Predicted translation: mọi thành công đều đến từ sự phấn đấu không biết mệt mỏi; mọi niềm hạnh phúc đều đến từ sự nỗ lực và kiên trì tưởng như bình thường nhất, bạn không thể tìm được con đường tắt.\n",
            "mọi thành công đều đến từ sự phấn đấu không biết mệt mỏi; mọi niềm hạnh phúc đều đến từ sự nỗ lực và kiên trì tưởng như bình thường nhất, bạn không thể tìm được con đường tắt.\n",
            "mọi thành công đều đến từ sự phấn đấu không biết mệt mỏi; mọi niềm hạnh phúc đều đến từ sự nỗ lực và kiên trì tưởng như bình thường nhất, bạn không thể tìm được con đường tắt.\n",
            "1.0\n",
            "Input: 别 人 在 熬 夜 的 时 候 ， 你 在 睡 觉 ； 别 人 已 经 起 床 ， 你 还 在 挣 扎 再 多 睡 几 分 钟 。 你 有 很 多 想 法 ， 但 脑 袋 热 了 就 过 了 ， 别 人 却 一 件 事 坚 持 到 底 。 你 连 一 本 书 都 要 看 很 久 ， 该 工 作 的 时 候 就 刷 起 手 机 ， 肯 定 也 不 能 早 晨 起 来 背 单 词 ， 晚 上 加 班 到 深 夜 。 很 多 时 候 不 是 你 平 凡 ， 碌 碌 无 为 ， 而 是 你 没 有 别 人 付 出 得 多 。\n",
            "Predicted translation: trong lúc người khác thức trắng đêm thì bạn đã ngủ say; khi người khác đã thức dậy thì bạn vẫn cố ngủ nướng thêm dăm ba phút. có rất nhiều ý muốn thì ra ngoài thì ra bạn không nghĩ của bạn như muốn nổ tung lên, liền bỏ thì vẫn muốn nổ tung lên, liền bầu trời thì vẫn nhất mà, thì vẫn sẽ không nghĩ ra sẽ không thể gọi là, thì tay bạn tiết nhất định sẽ không nghĩ ra nhiều chuyện mà thôi.\n",
            "trong lúc người khác thức trắng đêm thì bạn đã ngủ say; khi người khác đã thức dậy thì bạn vẫn cố ngủ nướng thêm dăm ba phút. bạn có rất nhiều ý tưởng, nhưng chúng lại khiến đầu óc bạn như muốn nổ tung lên, liền bỏ qua không nghĩ tiếp nữa, còn người khác thì vẫn kiên trì suy nghĩ đến cùng. đến cả một cuốn sách bạn cũng phải đọc rất lâu, lúc nên làm việc thì tay cầm điện thoại, chắc chắn bạn cũng sẽ không dậy từ sáng sớm để học từ mới, buổi tối sẽ không tăng ca đến tận đêm khuya. có nhiều khi không phải do bạn tầm thường, không có chí tiến thủ, mà là bạn chưa bỏ ra nhiều công sức bằng người khác.\n",
            "trong lúc người khác thức trắng đêm thì bạn đã ngủ say; khi người khác đã thức dậy thì bạn vẫn cố ngủ nướng thêm dăm ba phút. có rất nhiều ý muốn thì ra ngoài thì ra bạn không nghĩ của bạn như muốn nổ tung lên, liền bỏ thì vẫn muốn nổ tung lên, liền bầu trời thì vẫn nhất mà, thì vẫn sẽ không nghĩ ra sẽ không thể gọi là, thì tay bạn tiết nhất định sẽ không nghĩ ra nhiều chuyện mà thôi.\n",
            "0.27482015803238363\n",
            "Input: 当 一 个 人 忽 略 你 时 ， 不 要 伤 心 ， 每 个 人 都 有 自 己 的 生 活 ， 谁 都 不 可 能 一 直 陪 你 。 最 尴 尬 的 莫 过 于 高 估 自 己 在 别 人 心 里 的 位 置 ， 其 实 你 明 明 知 道 ， 最 卑 贱 不 过 感 情 ， 最 凉 不 过 人 心 。 是 你 的 ， 就 是 你 的 。 有 的 东 西 就 像 手 中 沙 ， 越 是 紧 握 ， 就 会 流 失 得 越 快 。 努 力 了 ， 珍 惜 了 ， 问 心 无 愧 。 其 他 的 ， 交 给 命 运 。\n",
            "Predicted translation: khi một người nào đó không quan tâm bạn, đừng quá đau lòng, mỗi người đều có cuộc sống của riêng mình, không ai có cơ hội là của hạnh phúc là ở trong quá cao vị trí của mọi thứ giống hệt nhau. không làm bạn mãi mang và càng khiến cho nhau, trong lòng người khác nhau, mãi mang theo gió vút lịch, cho bạn phải là lòng người khác và nước mắt tận hưởng nhưng cứ mãi mang đi.\n",
            "khi một người nào đó không quan tâm bạn, đừng quá đau lòng, mỗi người đều có cuộc sống của riêng mình, không ai có thể ở bên bạn mãi mãi. điều đáng xấu hổ nhất chính là đánh giá quá cao vị trí của bản thân trong lòng người khác, thực ra bạn biết đấy, rẻ tiền nhất là tình cảm, lạnh lẽo nhất là lòng người. cái gì của bạn sẽ mãi là của bạn. có những thứ giống như cát trong tay, càng nắm chặt sẽ trôi đi càng nhanh. bạn đã nỗ lực rồi, đã quý trọng rồi, cho nên bạn không thẹn với lương tâm. những thứ khác hãy để số phận quyết định.\n",
            "khi một người nào đó không quan tâm bạn, đừng quá đau lòng, mỗi người đều có cuộc sống của riêng mình, không ai có cơ hội là của hạnh phúc là ở trong quá cao vị trí của mọi thứ giống hệt nhau. không làm bạn mãi mang và càng khiến cho nhau, trong lòng người khác nhau, mãi mang theo gió vút lịch, cho bạn phải là lòng người khác và nước mắt tận hưởng nhưng cứ mãi mang đi.\n",
            "0.2563243413892937\n",
            "Input: 世 上 没 有 一 件 工 作 不 辛 苦 ， 没 有 一 处 人 事 不 复 杂 。 不 要 随 意 发 脾 气 ， 谁 都 不 欠 你 的 。 学 会 低 调 ， 取 舍 间 必 有 得 失 ， 不 用 太 计 较 。 学 着 踏 实 而 务 实 ， 越 努 力 越 幸 运 。 当 一 个 人 有 了 足 够 的 内 涵 和 物 质 做 后 盾 ， 人 生 就 会 变 得 底 气 十 足 。\n",
            "Predicted translation: trên đời này không có công việc nào là không cực nhọc, không có nơi nào chuyện đời, chuyện người là không phức tạp. đừng dễ dàng nổi nóng, bởi chẳng ai thiếu nợ bạn điều gì cả. khi đứng giữa sự lựa chọn hãy học cách đánh đổi, có được thì sẽ có mất, không nên quá tính toán chi li. hãy học cách làm việc thoải mái nhưng vẫn thiết thực, càng cố gắng sẽ càng có gì hồ của bạn. khi một người khác ngoại trừ mà trở nên mới có gì phải cắm trại này. khi bạn không có gì hào quang đáng để làm cho xong mà \"trưởng thành.\n",
            "trên đời này không có công việc nào là không cực nhọc, không có nơi nào chuyện đời, chuyện người là không phức tạp. đừng dễ dàng nổi nóng, bởi chẳng ai thiếu nợ bạn điều gì cả. khi đứng giữa sự lựa chọn hãy học cách đánh đổi, có được thì sẽ có mất, không nên quá tính toán chi li. hãy học cách làm việc thoải mái nhưng vẫn thiết thực, càng cố gắng sẽ càng có nhiều may mắn đến với bạn. khi một người đã được hậu thuẫn đầy đủ bởi tinh thần và vật chất, cuộc đời sẽ trở nên tràn đầy năng lượng.\n",
            "trên đời này không có công việc nào là không cực nhọc, không có nơi nào chuyện đời, chuyện người là không phức tạp. đừng dễ dàng nổi nóng, bởi chẳng ai thiếu nợ bạn điều gì cả. khi đứng giữa sự lựa chọn hãy học cách đánh đổi, có được thì sẽ có mất, không nên quá tính toán chi li. hãy học cách làm việc thoải mái nhưng vẫn thiết thực, càng cố gắng sẽ càng có gì hồ của bạn. khi một người khác ngoại trừ mà trở nên mới có gì phải cắm trại này. khi bạn không có gì hào quang đáng để làm cho xong mà \"trưởng thành.\n",
            "0.7173094866708452\n",
            "Input: 你 今 天 的 努 力 ， 是 幸 运 的 伏 笔 。 当 下 的 付 出 ， 是 明 日 的 花 开 。\n",
            "Predicted translation: những cố gắng ngày hôm nay của bạn là tiền đề cho sự may mắn sắp đến. điều bạn được nhận lại sẽ là những đóa hoa nở vào ngày mai.\n",
            "những cố gắng ngày hôm nay của bạn là tiền đề cho sự may mắn sắp đến. điều bạn được nhận lại sẽ là những đóa hoa nở vào ngày mai.\n",
            "những cố gắng ngày hôm nay của bạn là tiền đề cho sự may mắn sắp đến. điều bạn được nhận lại sẽ là những đóa hoa nở vào ngày mai.\n",
            "1.0\n",
            "Input: 不 管 昨 夜 经 历 了 怎 样 的 泣 不 成 声 ， 早 晨 醒 来 这 个 城 市 依 然 车 水 马 龙 。 开 心 或 者 不 开 心 ， 城 市 都 没 有 工 夫 等 ， 你 只 能 铭 记 或 者 遗 忘 。 那 一 站 你 爱 过 或 者 恨 过 的 旅 程 ， 那 一 段 你 拼 命 努 力 却 感 觉 不 到 希 望 的 日 子 ， 都 会 过 去 。\n",
            "Predicted translation: cho dù đêm qua bạn có khóc lóc, nức nở không thành tiếng đến thế nào thì sáng mai tỉnh dậy, thành phố này vẫn tấp nập người xe như cũ. dù bạn vui hay không vui thì thành phố cũng không hơi đâu mà đợi bạn, hoặc chịu cất thành phố cũng không an toàn, mượn duy nhất mà, mượn niềm tin vào lòng, bên cậu cùng thì chẳng còn có thể cất giấu trong đêm tối mà thôi.\n",
            "cho dù đêm qua bạn có khóc lóc, nức nở không thành tiếng đến thế nào thì sáng mai tỉnh dậy, thành phố này vẫn tấp nập người xe như cũ. dù bạn vui hay không vui thì thành phố cũng không hơi đâu mà đợi bạn, bạn chỉ có thể đem những cảm xúc ấy khắc sâu vào lòng, hoặc là quên đi. chặng đường mà bạn đã từng yêu từng hận đó, những tháng ngày bạn đã dốc hết sức lực nhưng vẫn không nhìn thấy hi vọng đó, tất cả rồi sẽ qua đi thôi.\n",
            "cho dù đêm qua bạn có khóc lóc, nức nở không thành tiếng đến thế nào thì sáng mai tỉnh dậy, thành phố này vẫn tấp nập người xe như cũ. dù bạn vui hay không vui thì thành phố cũng không hơi đâu mà đợi bạn, hoặc chịu cất thành phố cũng không an toàn, mượn duy nhất mà, mượn niềm tin vào lòng, bên cậu cùng thì chẳng còn có thể cất giấu trong đêm tối mà thôi.\n",
            "0.48643567600810383\n",
            "Input: 我 不 敢 休 息 ， 因 为 我 没 有 存 款 ； 我 不 敢 说 累 ， 因 为 我 没 有 成 就 ； 我 不 敢 偷 懒 ， 因 为 我 还 要 生 活 ； 我 能 放 弃 选 择 ， 但 是 我 不 能 选 择 放 弃 。 所 以 ， 坚 强 、 拼 搏 、 努 力 是 我 唯 一 的 选 择 。\n",
            "Predicted translation: tôi không dám nghỉ ngơi, bởi vì tôi vẫn chưa có một khoản tiền tiết kiệm nào; tôi vẫn chưa đạt được sự lựa chọn không dám kêu mệt, bởi vì tôi vẫn còn nhiều năm, bởi vì tôi vẫn còn phải sống; tôi vẫn còn phải nghĩ và nghĩ thông mọi việc, không thể nghĩ đến đựng cho sức lựa chọn diện sáng chế độ cho tôi vẫn còn gì mà thôi.\n",
            "tôi không dám nghỉ ngơi, bởi vì tôi vẫn chưa có một khoản tiền tiết kiệm nào; tôi không dám kêu mệt, bởi vì tôi vẫn chưa đạt được thành tựu gì; tôi không dám lười biếng, bởi vì tôi vẫn còn phải sống; tôi có thể từ bỏ quyền lựa chọn, nhưng tôi không thể lựa chọn từ bỏ. vì vậy, kiên cường, phấn đấu, nỗ lực chính là sự lựa chọn duy nhất của tôi.\n",
            "tôi không dám nghỉ ngơi, bởi vì tôi vẫn chưa có một khoản tiền tiết kiệm nào; tôi vẫn chưa đạt được sự lựa chọn không dám kêu mệt, bởi vì tôi vẫn còn nhiều năm, bởi vì tôi vẫn còn phải sống; tôi vẫn còn phải nghĩ và nghĩ thông mọi việc, không thể nghĩ đến đựng cho sức lựa chọn diện sáng chế độ cho tôi vẫn còn gì mà thôi.\n",
            "0.4616656571146197\n",
            "Input: 每 一 个 优 秀 的 人 ， 都 有 一 段 苦 逼 的 时 光 。 或 许 是 因 为 一 份 学 业 ， 一 份 工 作 ， 一 段 爱 情 ， 离 开 了 爸 爸 妈 妈 ， 去 了 一 座 别 的 城 市 。 当 你 倦 了 厌 了 时 ， 想 想 你 的 父 母 正 在 为 你 打 拼 ， 这 就 是 你 必 须 坚 强 的 理 由 。\n",
            "Predicted translation: mỗi con người tài giỏi, đều có một quãng thời gian khổ cực. có thể là vì chuyện bài vở học hành, vì công việc, chẳng còn chưa từng tới và chẳng biết nhiều, vì niềm vui vẻ, vì một ngày mai nước mắt. khi bạn muốn đem theo đuổi theo đuổi theo đuổi theo đuổi theo đuổi theo đuổi ra vì vậy ước mơ của tôi.\n",
            "mỗi con người tài giỏi, đều có một quãng thời gian khổ cực. có thể là vì chuyện bài vở học hành, vì công việc, vì tình yêu, phải rời xa cha mẹ đến một thành phố khác sinh sống. khi bạn đã mệt mỏi và phát chán rồi, hãy nghĩ đến công sức cha mẹ đang bỏ ra vì bạn, đây chính là lý do buộc bạn phải kiên cường.\n",
            "mỗi con người tài giỏi, đều có một quãng thời gian khổ cực. có thể là vì chuyện bài vở học hành, vì công việc, chẳng còn chưa từng tới và chẳng biết nhiều, vì niềm vui vẻ, vì một ngày mai nước mắt. khi bạn muốn đem theo đuổi theo đuổi theo đuổi theo đuổi theo đuổi theo đuổi ra vì vậy ước mơ của tôi.\n",
            "0.3664058633643218\n",
            "Input: 这 个 社 会 是 现 实 的 ， 你 没 有 实 力 的 时 候 ， 人 家 首 先 看 你 外 表 。 所 以 ， 当 你 没 有 外 表 的 时 候 ， 努 力 增 强 实 力 ， 当 你 既 没 外 表 又 没 实 力 的 时 候 ， 人 家 只 会 跟 你 说 ： 拜 拜 。\n",
            "Predicted translation: xã hội này rất thực tế, khi bạn không có thực lực, người ta sẽ nhìn vào vẻ bề ngoài của bạn. cho nên, khi bạn không có ngoại hình, phải cố gắng trau dồi thực lực, còn khi bạn không có cả ngoại hình lẫn thực lực, thì người ta sẽ chỉ nói với bạn: bye bye.\n",
            "xã hội này rất thực tế, khi bạn không có thực lực, người ta sẽ nhìn vào vẻ bề ngoài của bạn. cho nên, khi bạn không có ngoại hình, phải cố gắng trau dồi thực lực, còn khi bạn không có cả ngoại hình lẫn thực lực, thì người ta sẽ chỉ nói với bạn: bye bye.\n",
            "xã hội này rất thực tế, khi bạn không có thực lực, người ta sẽ nhìn vào vẻ bề ngoài của bạn. cho nên, khi bạn không có ngoại hình, phải cố gắng trau dồi thực lực, còn khi bạn không có cả ngoại hình lẫn thực lực, thì người ta sẽ chỉ nói với bạn: bye bye.\n",
            "1.0\n",
            "Input: 买 得 起 自 己 喜 欢 的 东 西 ， 去 得 了 自 己 想 去 的 地 方 ， 不 会 因 为 身 边 人 的 来 或 走 损 失 生 活 的 质 量 ， 反 而 会 因 为 花 自 己 的 钱 ， 来 得 更 有 底 气 一 些 ， 这 就 是 应 该 努 力 的 原 因 。\n",
            "Predicted translation: mua được thứ mình thích, đi tới nơi mình muốn đi, sẽ không vì sự đến hay đi của những người xung quanh mà làm ảnh hưởng đến chất lượng cuộc sống của mình. ngược lại, hãy vì được tiêu những đồng tiền do chính bản thân mình làm ra mà cảm thấy tràn đầy năng lượng, đó chính là nguyên nhân để bạn nỗ lực.\n",
            "mua được thứ mình thích, đi tới nơi mình muốn đi, sẽ không vì sự đến hay đi của những người xung quanh mà làm ảnh hưởng đến chất lượng cuộc sống của mình. ngược lại, hãy vì được tiêu những đồng tiền do chính bản thân mình làm ra mà cảm thấy tràn đầy năng lượng, đó chính là nguyên nhân để bạn nỗ lực.\n",
            "mua được thứ mình thích, đi tới nơi mình muốn đi, sẽ không vì sự đến hay đi của những người xung quanh mà làm ảnh hưởng đến chất lượng cuộc sống của mình. ngược lại, hãy vì được tiêu những đồng tiền do chính bản thân mình làm ra mà cảm thấy tràn đầy năng lượng, đó chính là nguyên nhân để bạn nỗ lực.\n",
            "1.0\n",
            "Input: 没 有 人 陪 你 走 一 辈 子 ， 所 以 你 要 适 应 孤 独 ； 没 有 人 会 帮 你 一 辈 子 ， 所 以 你 要 一 直 奋 斗 。\n",
            "Predicted translation: không một ai đi cùng bạn suốt đời, vì vậy bạn phải học cách làm quen với cô đơn; không một ai giúp bạn cả đời, vì vậy bạn phải không ngừng phấn đấu.\n",
            "không một ai đi cùng bạn suốt đời, vì vậy bạn phải học cách làm quen với cô đơn; không một ai giúp bạn cả đời, vì vậy bạn phải không ngừng phấn đấu.\n",
            "không một ai đi cùng bạn suốt đời, vì vậy bạn phải học cách làm quen với cô đơn; không một ai giúp bạn cả đời, vì vậy bạn phải không ngừng phấn đấu.\n",
            "1.0\n",
            "Input: 早 上 醒 来 时 ， 给 自 己 定 个 目 标 ： 今 天 一 定 要 比 昨 天 好 ！ 每 天 坚 持 ， 一 定 会 大 有 收 获 ！\n",
            "Predicted translation: buổi sáng mỗi khi thức dậy, hãy tự đặt cho mình một mục tiêu: hôm nay nhất định phải sống tốt hơn hôm qua! kiên trì mỗi ngày, chắc chắn bạn sẽ nhận được thu hoạch lớn.\n",
            "buổi sáng mỗi khi thức dậy, hãy tự đặt cho mình một mục tiêu: hôm nay nhất định phải sống tốt hơn hôm qua! kiên trì mỗi ngày, chắc chắn bạn sẽ nhận được thu hoạch lớn.\n",
            "buổi sáng mỗi khi thức dậy, hãy tự đặt cho mình một mục tiêu: hôm nay nhất định phải sống tốt hơn hôm qua! kiên trì mỗi ngày, chắc chắn bạn sẽ nhận được thu hoạch lớn.\n",
            "1.0\n",
            "Input: 静 下 心 来 好 好 做 你 该 做 的 事 ， 该 好 好 努 力 了 ！ 有 时 候 真 的 努 力 后 ， 你 会 发 现 自 己 要 比 想 象 得 优 秀 很 多 。\n",
            "Predicted translation: tĩnh tâm lại và làm tốt những việc bạn cần làm, hãy cố gắng thật nhiều nhé! có đôi lúc khi đã thực sự cố gắng, bạn sẽ nhận ra bạn còn tài giỏi hơn mình tưởng rất nhiều.\n",
            "tĩnh tâm lại và làm tốt những việc bạn cần làm, hãy cố gắng thật nhiều nhé! có đôi lúc khi đã thực sự cố gắng, bạn sẽ nhận ra bạn còn tài giỏi hơn mình tưởng rất nhiều.\n",
            "tĩnh tâm lại và làm tốt những việc bạn cần làm, hãy cố gắng thật nhiều nhé! có đôi lúc khi đã thực sự cố gắng, bạn sẽ nhận ra bạn còn tài giỏi hơn mình tưởng rất nhiều.\n",
            "1.0\n",
            "Input: 悄 悄 地 去 努 力 ， 等 变 厉 害 之 后 ， 蹦 出 来 把 曾 经 看 不 起 自 己 的 人 吓 一 大 跳 ， 才 是 你 现 在 需 要 当 作 目 标 的 事 。\n",
            "Predicted translation: hãy cứ lặng lẽ mà cố gắng, chờ đến khi bạn trở nên tài giỏi rồi, sẽ phá kén chui ra, dọa cho những kẻ từng khinh thường bạn một phen giật mình, đó mới là mục tiêu bạn cần làm lúc này.\n",
            "hãy cứ lặng lẽ mà cố gắng, chờ đến khi bạn trở nên tài giỏi rồi, sẽ phá kén chui ra, dọa cho những kẻ từng khinh thường bạn một phen giật mình, đó mới là mục tiêu bạn cần làm lúc này.\n",
            "hãy cứ lặng lẽ mà cố gắng, chờ đến khi bạn trở nên tài giỏi rồi, sẽ phá kén chui ra, dọa cho những kẻ từng khinh thường bạn một phen giật mình, đó mới là mục tiêu bạn cần làm lúc này.\n",
            "1.0\n",
            "Input: 你 的 努 力 ， 也 许 有 人 会 讥 讽 ； 你 的 执 着 ， 也 许 不 会 有 人 读 懂 。 在 别 人 眼 里 你 也 许 是 小 丑 ， 但 在 自 己 心 中 你 就 是 女 王 ！\n",
            "Predicted translation: có lẽ sẽ có người mỉa mai sự nỗ lực của bạn; có lẽ sẽ có người không hiểu được những suy nghĩ cố gắng khiến cậu là một tên khác bạn mà chỉ là một tên hề chấp của bạn.\n",
            "có lẽ sẽ có người mỉa mai sự nỗ lực của bạn; có lẽ sẽ có người không hiểu được những suy nghĩ cố chấp của bạn. trong mắt người khác bạn có thể là một tên hề mua vui, nhưng trong trái tim mình, bạn chính là nữ hoàng!\n",
            "có lẽ sẽ có người mỉa mai sự nỗ lực của bạn; có lẽ sẽ có người không hiểu được những suy nghĩ cố gắng khiến cậu là một tên khác bạn mà chỉ là một tên hề chấp của bạn.\n",
            "0.5518282797107956\n",
            "Input: 纵 然 我 没 有 惊 世 才 华 ， 纵 然 我 没 有 丰 厚 财 富 ， 但 是 我 有 满 腔 的 激 情 ， 我 有 乐 观 的 态 度 ， 因 为 我 相 信 ： 只 要 努 力 ， 一 切 皆 有 可 能 ！\n",
            "Predicted translation: cho dù tôi không có tài hoa tuyệt thế, cũng không có nhiều tiền của, nhưng tôi có tấm lòng tràn đầy đam mê và tinh thần lạc quan vui vẻ, bởi vì tôi tin rằng: chỉ có thể thực ra chưa bao giờ có thể thực hiện được!\n",
            "cho dù tôi không có tài hoa tuyệt thế, cũng không có nhiều tiền của, nhưng tôi có tấm lòng tràn đầy đam mê và tinh thần lạc quan vui vẻ, bởi vì tôi tin rằng: chỉ cần cố gắng, chuyện gì cũng có thể thực hiện được!\n",
            "cho dù tôi không có tài hoa tuyệt thế, cũng không có nhiều tiền của, nhưng tôi có tấm lòng tràn đầy đam mê và tinh thần lạc quan vui vẻ, bởi vì tôi tin rằng: chỉ có thể thực ra chưa bao giờ có thể thực hiện được!\n",
            "0.8199277649246208\n",
            "Input: 有 时 候 ， 努 力 一 点 ， 是 为 让 自 己 有 资 格 ， 不 去 做 不 喜 欢 的 事 ； 为 了 能 让 自 己 ， 遇 见 一 个 喜 欢 的 人 时 ， 不 会 因 为 ， 自 己 不 够 好 而 没 能 留 住 对 方 ； 为 了 避 免 ， 与 朋 友 拉 开 差 距 未 来 也 能 看 到 同 一 个 世 界 ； 为 了 看 清 自 己 最 后 能 走 到 哪 里\n",
            "Predicted translation: có đôi khi, nỗ lực thêm một chút là vì để bản thân có tư cách, không phải làm những việc mình không thích không thích làm; vì để khi gặp được người mình thích, không vì bản thân không đủ tốt mà không níu giữ được đối phương; vì để tránh có một tương lai kém xa bạn bè, được cùng họ ngắm chung một thế giới; vì để nhìn cho rõ rằng, đến cuối cùng mình có thể đi được đến đâu.\n",
            "có đôi khi, nỗ lực thêm một chút là vì để bản thân có tư cách, không phải làm những việc mình không thích làm; vì để khi gặp được người mình thích, sẽ không vì bản thân không đủ tốt mà không níu giữ được đối phương; vì để tránh có một tương lai kém xa bạn bè, được cùng họ ngắm chung một thế giới; vì để nhìn cho rõ rằng, đến cuối cùng mình có thể đi được đến đâu.\n",
            "có đôi khi, nỗ lực thêm một chút là vì để bản thân có tư cách, không phải làm những việc mình không thích không thích làm; vì để khi gặp được người mình thích, không vì bản thân không đủ tốt mà không níu giữ được đối phương; vì để tránh có một tương lai kém xa bạn bè, được cùng họ ngắm chung một thế giới; vì để nhìn cho rõ rằng, đến cuối cùng mình có thể đi được đến đâu.\n",
            "0.9541153082958899\n",
            "Input: 成 功 酝 酿 于 好 的 品 质 ， 不 要 松 懈 精 神 上 的 追 求 ； 演 好 自 己 的 角 色 ， 做 好 职 责 内 的 事 情 ， 防 止 轻 易 越 位 ； 一 旦 确 定 目 标 ， 就 死 死 地 盯 着 它 ； 不 要 害 怕 竞 争 ， 没 有 竞 争 ， 生 存 就 失 去 了 意 义 。\n",
            "Predicted translation: để nuôi dưỡng phẩm chất của một người thành công, chớ coi nhẹ tinh thần cầu tiến; hãy phát huy tốt vai trò của bản thân, hoàn thành tốt công việc trong phạm vi chức trách của mình, hoàn thiện nước nóng và hoàn thiện hơn.\n",
            "để nuôi dưỡng phẩm chất của một người thành công, chớ coi nhẹ tinh thần cầu tiến; hãy phát huy tốt vai trò của bản thân, hoàn thành tốt công việc trong phạm vi chức trách của mình, tránh vượt quyền; khi đã xác định được mục tiêu thì hãy chuyên tâm đến nó; đừng sợ cạnh tranh, bởi nếu không có cạnh tranh, sự sống còn ý nghĩa gì nữa.\n",
            "để nuôi dưỡng phẩm chất của một người thành công, chớ coi nhẹ tinh thần cầu tiến; hãy phát huy tốt vai trò của bản thân, hoàn thành tốt công việc trong phạm vi chức trách của mình, hoàn thiện nước nóng và hoàn thiện hơn.\n",
            "0.47625164343818455\n",
            "Input: 不 知 道 什 么 艰 难 困 苦 ， 只 知 道 风 雨 无 阻 ； 不 知 道 什 么 悲 伤 无 助 ， 只 知 道 天 无 绝 路 ； 不 知 道 什 么 失 败 惨 楚 ， 只 知 道 昂 首 阔 步 ； 不 知 道 什 么 荆 棘 密 布 ， 只 知 道 毅 然 走 去 - - 成 功 ， 就 在 彼 岸 ！\n",
            "Predicted translation: không biết khó khăn là, chỉ biết gió táp mưa sa cũng không ngăn nổi bước chân đi; không biết đau thương là gì, chỉ biết trời sẽ không biết bụi rậm chông gai là gì, chỉ biết ngẩng đầu hiên ngang tiến về phía trước.\n",
            "không biết khó khăn là, chỉ biết gió táp mưa sa cũng không ngăn nổi bước chân đi; không biết đau thương là gì, chỉ biết trời sẽ không tuyệt đường người; không biết thất bại thảm hại là gì, chỉ biết ngẩng đầu hiên ngang tiến về phía trước; không biết bụi rậm chông gai là gì, chỉ biết cứ tiếp tục đi - thành công, ở ngay bờ bên kia.\n",
            "không biết khó khăn là, chỉ biết gió táp mưa sa cũng không ngăn nổi bước chân đi; không biết đau thương là gì, chỉ biết trời sẽ không biết bụi rậm chông gai là gì, chỉ biết ngẩng đầu hiên ngang tiến về phía trước.\n",
            "0.5455065310151127\n",
            "Input: 每 个 人 都 有 觉 得 自 己 不 够 好 ， 羡 慕 别 人 闪 闪 发 光 的 时 候 ， 但 其 实 大 多 人 都 是 普 通 的 。 不 要 沮 丧 ， 不 必 惊 慌 ， 做 努 力 爬 的 蜗 牛 或 坚 持 飞 的 笨 鸟 ， 在 最 平 凡 的 生 活 里 ， 谦 卑 和 努 力 。 总 有 一 天 ， 你 会 站 在 最 亮 的 地 方 ， 活 成 自 己 曾 经 渴 望 的 模 样 。\n",
            "Predicted translation: mỗi người đều có lúc cảm thấy bản thân không đủ tốt, ngưỡng mộ giây phút người khác khoác trên mình ánh hào quang huy hoàng; nhưng thực ra, phần lớn mọi người đều chỉ là người bình thường. bạn đừng chán nản, đừng hoang mang, hãy làm một chú ốc sên luôn cố gắng bò từng bước chậm rãi về phía trước, hoặc làm một chú chim ngốc nghếch luôn kiên trì tập bay lên cao, hãy khiêm tốn và nỗ lực mà sống trong cuộc sống bình thường này. sẽ có một ngày, bạn sẽ được đứng ở nơi sáng chói nhất, trở thành dáng vẻ mà bạn vẫn luôn ao ước.\n",
            "mỗi người đều có lúc cảm thấy bản thân không đủ tốt, ngưỡng mộ giây phút người khác khoác trên mình ánh hào quang huy hoàng; nhưng thực ra, phần lớn mọi người đều chỉ là người bình thường. bạn đừng chán nản, đừng hoang mang, hãy làm một chú ốc sên luôn cố gắng bò từng bước chậm rãi về phía trước, hoặc làm một chú chim ngốc nghếch luôn kiên trì tập bay lên cao, hãy khiêm tốn và nỗ lực mà sống trong cuộc sống bình thường này. sẽ có một ngày, bạn sẽ được đứng ở nơi sáng chói nhất, trở thành dáng vẻ mà bạn vẫn luôn ao ước.\n",
            "mỗi người đều có lúc cảm thấy bản thân không đủ tốt, ngưỡng mộ giây phút người khác khoác trên mình ánh hào quang huy hoàng; nhưng thực ra, phần lớn mọi người đều chỉ là người bình thường. bạn đừng chán nản, đừng hoang mang, hãy làm một chú ốc sên luôn cố gắng bò từng bước chậm rãi về phía trước, hoặc làm một chú chim ngốc nghếch luôn kiên trì tập bay lên cao, hãy khiêm tốn và nỗ lực mà sống trong cuộc sống bình thường này. sẽ có một ngày, bạn sẽ được đứng ở nơi sáng chói nhất, trở thành dáng vẻ mà bạn vẫn luôn ao ước.\n",
            "1.0\n",
            "Input: 后 来 才 明 白 ， 要 赚 到 足 够 令 自 己 安 心 的 钱 ， 才 能 过 上 简 单 、 安 逸 、 自 由 的 生 活 ， 才 能 让 自 己 活 得 更 有 底 气 。 所 以 ， 多 花 时 间 努 力 ， 少 点 工 夫 矫 情 。\n",
            "Predicted translation: sau này bạn sẽ hiểu, phải kiếm được đủ khoản tiền khiến bản thân yên tâm, bạn mới có thể sống một cuộc sống đơn giản, để an nhàn và tự do, mới có thể khiến bản thân sống càng hăng hái, nhiệt tình. bởi vậy, hãy dành nhiều thời gian để phê bình soi mói.\n",
            "sau này bạn sẽ hiểu, phải kiếm được đủ khoản tiền khiến bản thân yên tâm, bạn mới có thể sống một cuộc sống đơn giản, an nhàn và tự do, mới có thể khiến bản thân sống càng hăng hái, nhiệt tình. bởi vậy, hãy dành nhiều thời gian để nỗ lực hơn là để phê bình soi mói.\n",
            "sau này bạn sẽ hiểu, phải kiếm được đủ khoản tiền khiến bản thân yên tâm, bạn mới có thể sống một cuộc sống đơn giản, để an nhàn và tự do, mới có thể khiến bản thân sống càng hăng hái, nhiệt tình. bởi vậy, hãy dành nhiều thời gian để phê bình soi mói.\n",
            "0.8781259649429565\n",
            "Input: 一 个 不 努 力 的 人 ， 别 人 想 拉 你 一 把 ， 都 找 不 到 你 的 手 在 哪 里 。\n",
            "Predicted translation: một người không cố gắng chính là, người khác muốn giúp bạn một tay, cũng không biết tay bạn đang ở đâu.\n",
            "một người không cố gắng chính là, người khác muốn giúp bạn một tay, cũng không biết tay bạn đang ở đâu.\n",
            "một người không cố gắng chính là, người khác muốn giúp bạn một tay, cũng không biết tay bạn đang ở đâu.\n",
            "1.0\n",
            "Input: 一 个 人 的 豁 达 ， 体 现 在 落 魄 的 时 候 。 一 个 人 的 涵 养 ， 体 现 在 愤 怒 的 时 候 。 一 个 人 的 体 贴 ， 体 现 在 悲 伤 的 时 候 。 一 个 人 的 成 熟 ， 体 现 在 抉 择 的 时 候 。 谁 都 愿 意 做 自 己 喜 欢 的 事 情 ， 可 是 ， 做 你 该 做 的 事 情 ， 才 叫 成 长 。\n",
            "Predicted translation: một người cởi mở, thể hiện rõ nhất khi họ chán nản. một người biết tiết chế, thể hiện rõ nhất khi họ tức giận. một người săn sóc chu đáo, thể hiện rõ nhất khi họ đau thương. một người chín chắn, thể hiện rõ nhất khi họ đưa ra lựa chọn. bất cứ ai cũng muốn được làm điều mình thích, nhưng làm điều mình nên làm, mới được gọi là \"trưởng thành\".\n",
            "một người cởi mở, thể hiện rõ nhất khi họ chán nản. một người biết tiết chế, thể hiện rõ nhất khi họ tức giận. một người săn sóc chu đáo, thể hiện rõ nhất khi họ đau thương. một người chín chắn, thể hiện rõ nhất khi họ đưa ra lựa chọn. bất cứ ai cũng muốn được làm điều mình thích, nhưng làm điều mình nên làm, mới được gọi là \"trưởng thành\".\n",
            "một người cởi mở, thể hiện rõ nhất khi họ chán nản. một người biết tiết chế, thể hiện rõ nhất khi họ tức giận. một người săn sóc chu đáo, thể hiện rõ nhất khi họ đau thương. một người chín chắn, thể hiện rõ nhất khi họ đưa ra lựa chọn. bất cứ ai cũng muốn được làm điều mình thích, nhưng làm điều mình nên làm, mới được gọi là \"trưởng thành\".\n",
            "1.0\n",
            "Input: 如 果 有 人 不 拿 你 当 回 事 ， 没 必 要 因 此 生 气 ， 更 别 铆 足 了 劲 儿 去 表 现 ， 非 要 证 明 自 己 多 出 色 ， 这 样 做 会 累 死 你 ， 因 为 拿 你 不 当 一 回 事 的 人 多 着 呢 ， 你 无 法 满 足 所 有 人 的 眼 光 。 最 好 的 办 法 是 谁 不 在 乎 你 ， 你 也 不 必 在 乎 他 。 不 必 为 别 人 的 一 两 句 话 就 改 变 自 己 对 自 己 的 看 法 ， 自 己 是 怎 样 继 续 怎 样 ， 你 的 努 力 ， 只 是 为 了 自 己 。\n",
            "Predicted translation: nếu không được người khác xem trọng, bạn không cần tức giận, càng không nên tỏ thái độ ra ngoài, không việc gì phải chứng minh mình xuất sắc, làm như vậy bạn sẽ rất mệt mỏi, bởi vì có rất nhiều người không coi trọng bạn, bạn không thể nào làm tốt nhất định mọi người. biện pháp tốt nhất chính là, để sự mà đừng quan tâm những người không quan tâm bạn. chớ vì một hai câu của người khác mà thôi.\n",
            "nếu không được người khác xem trọng, bạn không cần tức giận, càng không nên tỏ thái độ ra ngoài, không việc gì phải chứng minh mình xuất sắc, làm như vậy bạn sẽ rất mệt mỏi, bởi vì có rất nhiều người không coi trọng bạn, bạn không thể nào làm hài lòng tất cả mọi người. biện pháp tốt nhất chính là, đừng quan tâm những người không quan tâm bạn. chớ vì một hai câu của người khác mà thay đổi cách nhìn về bản thân, hãy cứ là chính mình, mọi nỗ lực của bạn đều bỏ ra vì chính bạn.\n",
            "nếu không được người khác xem trọng, bạn không cần tức giận, càng không nên tỏ thái độ ra ngoài, không việc gì phải chứng minh mình xuất sắc, làm như vậy bạn sẽ rất mệt mỏi, bởi vì có rất nhiều người không coi trọng bạn, bạn không thể nào làm tốt nhất định mọi người. biện pháp tốt nhất chính là, để sự mà đừng quan tâm những người không quan tâm bạn. chớ vì một hai câu của người khác mà thôi.\n",
            "0.6950241371655006\n",
            "Input: 你 勤 奋 充 电 ， 你 努 力 工 作 ， 你 保 持 身 材 ， 你 对 人 微 笑 ， 这 些 都 不 是 为 了 取 悦 他 人 ， 而 是 为 了 扮 靓 自 己 ， 照 亮 自 己 的 心 ， 告 诉 自 己 ： 我 是 一 股 独 立 向 上 的 力 量 。\n",
            "Predicted translation: bạn nỗ lực rèn luyện bản thân, bạn làm việc chăm chỉ, bạn giữ gìn vóc dáng hay bạn mỉm cười với mọi người. đây vốn chẳng phải là để làm hài lòng người khác mà để làm hài lòng người khác mà để làm hài lòng người khác rằng cậu là để làm hài lòng người khác mà để xứng đáng với mọi người. đây chính là để nhận ra rằng, tầm mắt ngưỡng mộ người khác nhất định mà bạn để làm những người khác mà thôi.\n",
            "bạn nỗ lực rèn luyện bản thân, bạn làm việc chăm chỉ, bạn giữ gìn vóc dáng hay bạn mỉm cười với mọi người. đây vốn chẳng phải là để làm hài lòng người khác mà để tự làm đẹp cho mình, thanh lọc tâm hồn người mình. tự nhủ rằng tôi chính là một con người độc lập luôn mạnh mẽ tiến về phía trước.\n",
            "bạn nỗ lực rèn luyện bản thân, bạn làm việc chăm chỉ, bạn giữ gìn vóc dáng hay bạn mỉm cười với mọi người. đây vốn chẳng phải là để làm hài lòng người khác mà để làm hài lòng người khác mà để làm hài lòng người khác rằng cậu là để làm hài lòng người khác mà để xứng đáng với mọi người. đây chính là để nhận ra rằng, tầm mắt ngưỡng mộ người khác nhất định mà bạn để làm những người khác mà thôi.\n",
            "0.42396664420662566\n",
            "Input: 做 最 大 的 努 力 ， 做 最 壞 的 打 算 ， 便 無 所 畏 懼 ； 做 最 多 的 付 出 ， 做 最 小 的 期 待 ， 便 不 會 失 意 ； 做 最 美 的 夢 ， 過 現 實 的 生 活 ， 便 不 會 無 趣 。 生 活 ， 準 備 得 如 何 ， 就 如 何 去 應 對 。\n",
            "Predicted translation: duy trì những nổ lực lớn nhất, chuẩn bị cho những tình huống xấu nhất, lúc đó bạn sẽ chẳng còn phải sợ gì cả. hi sinh nhiều, kì vọng ít - bạn sẽ không phải chịu cảm giác thất vọng nhiều lắm đâu. hãy tạo cho mình những giấc mơ đẹp đẽ và cũng hãy sống một cách thực tế - bạn sẽ không thấy nhàm chán. cuộc sống mà, bạn chuẩn bị đến đâu thì đối mặt đến đó thôi!\n",
            "duy trì những nổ lực lớn nhất, chuẩn bị cho những tình huống xấu nhất, lúc đó bạn sẽ chẳng còn phải sợ gì cả. hi sinh nhiều, kì vọng ít - bạn sẽ không phải chịu cảm giác thất vọng nhiều lắm đâu. hãy tạo cho mình những giấc mơ đẹp đẽ và cũng hãy sống một cách thực tế - bạn sẽ không thấy nhàm chán. cuộc sống mà, bạn chuẩn bị đến đâu thì đối mặt đến đó thôi!\n",
            "duy trì những nổ lực lớn nhất, chuẩn bị cho những tình huống xấu nhất, lúc đó bạn sẽ chẳng còn phải sợ gì cả. hi sinh nhiều, kì vọng ít - bạn sẽ không phải chịu cảm giác thất vọng nhiều lắm đâu. hãy tạo cho mình những giấc mơ đẹp đẽ và cũng hãy sống một cách thực tế - bạn sẽ không thấy nhàm chán. cuộc sống mà, bạn chuẩn bị đến đâu thì đối mặt đến đó thôi!\n",
            "1.0\n",
            "Input: 人 生 路 上 会 有 美 丽 的 风 景 等 待 我 们 去 欣 赏 ， 该 来 的 不 要 躲 闪 ， 该 去 的 不 要 纠 缠 ， 该 做 的 勇 于 担 当 ； 把 该 放 弃 的 让 它 随 风 而 去 ， 不 要 抓 住 不 放 ； 把 该 留 下 的 藏 在 记 忆 深 处 ， 尘 封 起 来 ； 把 曾 经 的 坎 坷 和 磨 难 沉 淀 成 珍 贵 的 财 富 ， 鞭 策 我 们 前 行 。\n",
            "Predicted translation: trên con đường đời còn có biết bao nhiêu phong cảnh đẹp đang chờ chúng ta thưởng ngoạn. điều gì sẽ đến thì không cần trốn tránh, nơi nào có gì nên chần chừ, nơi đừng cố gắng níu giữ lại khiến bản thân yêu thương để những gì nên từ bỏ trôi theo gió bay, đừng cố gắng níu kéo. hãy vì những gì cần giữ lại được chôn sâu trong thâm tâm, phủ đầy lớp bụi thời gian. hãy để những khó khăn thử thách đã từng trải những khó khăn thử thách đã từng trải những tài giỏi thì trở thành công.\n",
            "trên con đường đời còn có biết bao nhiêu phong cảnh đẹp đang chờ chúng ta thưởng ngoạn. điều gì sẽ đến thì không cần trốn tránh, nơi nào cần đi không nên chần chừ, những việc cần làm phải dũng cảm đảm nhận. hãy để những gì nên từ bỏ trôi theo gió bay, đừng cố gắng níu kéo. hãy vì những gì cần giữ lại được chôn sâu trong thâm tâm, phủ đầy lớp bụi thời gian. hãy để những khó khăn thử thách đã từng trải qua lắng đọng, kết tinh thành những tài sản quý giá và trở thành động lực thúc giục chúng ta luôn tiến bước về phía trước.\n",
            "trên con đường đời còn có biết bao nhiêu phong cảnh đẹp đang chờ chúng ta thưởng ngoạn. điều gì sẽ đến thì không cần trốn tránh, nơi nào có gì nên chần chừ, nơi đừng cố gắng níu giữ lại khiến bản thân yêu thương để những gì nên từ bỏ trôi theo gió bay, đừng cố gắng níu kéo. hãy vì những gì cần giữ lại được chôn sâu trong thâm tâm, phủ đầy lớp bụi thời gian. hãy để những khó khăn thử thách đã từng trải những khó khăn thử thách đã từng trải những tài giỏi thì trở thành công.\n",
            "0.641805439135153\n",
            "Input: 如 果 黑 暗 和 光 明 让 你 去 选 择 ， 你 最 好 选 择 相 信 光 明 ， 因 为 光 明 会 让 你 看 见 希 望 ， 而 黑 暗 里 永 远 只 有 绝 望 。 即 便 你 从 未 看 见 过 光 明 ， 你 也 要 选 择 相 信 ， 在 信 仰 里 活 着 不 会 让 你 的 生 活 处 处 只 是 一 潭 死 水 。\n",
            "Predicted translation: nếu để bạn lựa chọn giữa bóng tối và ánh sáng thì tốt nhất bạn nên lựa chọn tin tưởng vào ánh sáng. bởi vì ánh sáng sẽ cho bạn hy vọng còn trong màn đêm u tối chỉ tồn tại sự tuyệt vọng mà thôi. cho dù bạn chưa từng nhìn thấy ánh sáng thì cũng hãy cứ tin tưởng mà đưa cho nó, sống trong niềm tin của tín ngưỡng, cuộc sống của bạn nhất định sẽ không thành một đầm lầy chết.\n",
            "nếu để bạn lựa chọn giữa bóng tối và ánh sáng thì tốt nhất bạn nên lựa chọn tin tưởng vào ánh sáng. bởi vì ánh sáng sẽ cho bạn hy vọng còn trong màn đêm u tối chỉ tồn tại sự tuyệt vọng mà thôi. cho dù bạn chưa từng nhìn thấy ánh sáng thì cũng hãy cứ tin tưởng mà đưa cho nó, sống trong niềm tin của tín ngưỡng, cuộc sống của bạn nhất định sẽ không thành một đầm lầy chết.\n",
            "nếu để bạn lựa chọn giữa bóng tối và ánh sáng thì tốt nhất bạn nên lựa chọn tin tưởng vào ánh sáng. bởi vì ánh sáng sẽ cho bạn hy vọng còn trong màn đêm u tối chỉ tồn tại sự tuyệt vọng mà thôi. cho dù bạn chưa từng nhìn thấy ánh sáng thì cũng hãy cứ tin tưởng mà đưa cho nó, sống trong niềm tin của tín ngưỡng, cuộc sống của bạn nhất định sẽ không thành một đầm lầy chết.\n",
            "1.0\n",
            "Input: 永 不 要 羡 慕 那 些 生 而 富 贵 的 人 。 物 质 世 界 无 穷 尽 ， 最 重 要 的 不 是 拥 有 什 么 ， 而 是 努 力 改 善 ， 使 生 活 充 满 希 望 ， 使 生 命 每 天 向 上 。 不 要 求 你 有 钱 ， 但 是 要 答 应 我 ， 明 年 ， 下 个 月 ， 明 天 ， 都 比 现 在 多 一 点 。\n",
            "Predicted translation: đừng bao giờ ngưỡng mộ những người giầu từ trong trứng. thế giới vật chất như một hố đen không đáy, điều quan trọng nhất không phải bạn có trong tay cái gì mà là sự cố gắng thay đổi để được trở nên tốt hơn, để xứng đáng để mỗi ngày nhất không phải tiếp tục cố gắng sống trở nên xa lạ với một người khác nhau, sống trong tay trọng nhất định, sống của lớp bụi thời gian. có gì phải là một vài ngày mai.\n",
            "đừng bao giờ ngưỡng mộ những người giầu từ trong trứng. thế giới vật chất như một hố đen không đáy, điều quan trọng nhất không phải bạn có trong tay cái gì mà là sự cố gắng thay đổi để được trở nên tốt hơn, để cuộc sống tràn đầy hy vọng và để mỗi ngày đều tiến về phía trước. tôi không yêu cầu bạn phải có tiền nhưng hãy hứa với tôi: ngày mai, tháng sau, năm sau, đều phải có gì đó nhiều hơn hiện tại.\n",
            "đừng bao giờ ngưỡng mộ những người giầu từ trong trứng. thế giới vật chất như một hố đen không đáy, điều quan trọng nhất không phải bạn có trong tay cái gì mà là sự cố gắng thay đổi để được trở nên tốt hơn, để xứng đáng để mỗi ngày nhất không phải tiếp tục cố gắng sống trở nên xa lạ với một người khác nhau, sống trong tay trọng nhất định, sống của lớp bụi thời gian. có gì phải là một vài ngày mai.\n",
            "0.5534856129307234\n",
            "Input: 人 生 就 是 一 场 未 知 的 冒 险 ， 没 有 人 会 事 先 知 道 结 局 。 别 人 只 会 尊 重 你 的 选 择 ， 而 不 会 在 意 你 的 牺 牲 。 所 以 ， 不 要 怨 天 尤 人 ， 而 应 当 冷 静 地 面 对 目 前 的 状 况 ， 用 心 并 且 负 责 地 去 解 决 现 在 的 问 题 。 只 要 能 对 自 己 的 现 在 负 责 ， 那 么 未 来 也 会 为 你 负 责 ！\n",
            "Predicted translation: đời người là thần thoại tuyệt vời mãi chẳng mong muốn mà thôi. điều gì và mỗi con đường có ai không đề hài lòng đừng lãng phí điều quan khổ tốt nhất. có gì sẽ chẳng còn phải là sự lựa chọn đúng yêu thương nhất là để khi chúng ta phải là để mỗi con gái mà phải không níu kéo. hãy vì những gì phải có lớp bụi bạn sẽ được hoàn hảo hơn và tiếp tục cố gắng phận tự làm tốt đẹp nhất. hãy cứ như cứ một vài sự thật; không quan trọng. hãy cứ tiến về phía trước bởi vì những gì bạn. hãy làm tốt những thứ sẽ trở nên mới xảy ra mạnh mẽ hơn.\n",
            "cuộc sống là một cuộc mạo hiểm không thể lường trước được điều gì và chẳng có ai đoán được kết cục sẽ đi về đâu. vì thế đừng bao giờ than trời trách đất mà hãy bình tĩnh đối mặt với mọi điều xảy ra trước mắt, có tâm và tinh thần trách nhiệm giải quyết mọi vấn đề. chỉ cần bạn có trách nhiệm với cuộc sống hiện tại của bản thân thì tương lai sẽ không phụ lại bạn.\n",
            "đời người là thần thoại tuyệt vời mãi chẳng mong muốn mà thôi. điều gì và mỗi con đường có ai không đề hài lòng đừng lãng phí điều quan khổ tốt nhất. có gì sẽ chẳng còn phải là sự lựa chọn đúng yêu thương nhất là để khi chúng ta phải là để mỗi con gái mà phải không níu kéo. hãy vì những gì phải có lớp bụi bạn sẽ được hoàn hảo hơn và tiếp tục cố gắng phận tự làm tốt đẹp nhất. hãy cứ như cứ một vài sự thật; không quan trọng. hãy cứ tiến về phía trước bởi vì những gì bạn. hãy làm tốt những thứ sẽ trở nên mới xảy ra mạnh mẽ hơn.\n",
            "0.08808112416902608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input: 十 年 前 你 是 谁 ， 一 年 前 你 是 谁 ， 甚 至 昨 天 你 是 谁 ， 都 不 重 要 。 重 要 的 是 ， 今 天 你 是 谁 ， 以 及 明 天 你 将 成 为 谁 。\n",
            "Predicted translation: 10 năm trước bạn là ai, một năm trước bạn là ai, thậm chí ngày hôm qua bạn là ai tất cả đều không quan trọng. điều quan trọng. điều quan trọng là: hôm nay bạn sẽ trở nên ngày mai bạn sẽ trở thành người như thế nào.\n",
            "10 năm trước bạn là ai, một năm trước bạn là ai, thậm chí ngày hôm qua bạn là ai, tất cả đều không quan trọng. điều quan trọng là: hôm nay bạn là ai và ngày mai bạn sẽ trở thành người như thế nào.\n",
            "10 năm trước bạn là ai, một năm trước bạn là ai, thậm chí ngày hôm qua bạn là ai tất cả đều không quan trọng. điều quan trọng. điều quan trọng là: hôm nay bạn sẽ trở nên ngày mai bạn sẽ trở thành người như thế nào.\n",
            "0.8016554989550111\n",
            "Input: 人 生 处 处 有 风 景 ， 何 不 适 时 停 一 停 ？ 不 企 求 与 山 巅 观 日 月 ， 只 是 因 峰 外 还 有 峰 。 人 生 之 路 上 没 有 什 么 艰 难 的 ， 把 困 难 当 作 一 阵 风 就 好 了 。 我 坚 信 ， 只 要 肯 努 力 ， 未 来 定 会 成 功 ！\n",
            "Predicted translation: đời người chốn nào cũng có cảnh đẹp, sao không lựa lúc thích hợp mà đứng lại thưởng ngoạn? đừng mong muốn được đứng trên đỉnh núi cao mà ngắm nhìn đất trời, bởi núi khác cao còn có núi khác cao còn có gì là quá cao mà thôi. đời người chẳng có gì tầm mắt thứ đều có gì là chụp mơ thì chúng ta thắp lên núi nào mà \"nước mắt ngưỡng mộ nhau.\n",
            "đời người chốn nào cũng có cảnh đẹp, sao không lựa lúc thích hợp mà đứng lại thưởng ngoạn? đừng mong muốn được đứng trên đỉnh núi cao mà ngắm nhìn đất trời, bởi núi cao còn có núi khác cao hơn. đời người chẳng có gì là quá khó khăn cả nên hãy coi những thử thách ấy như một trận gió vút qua. tôi tin rằng, chỉ cần mình đủ cố gắng thì tương lai nhất định sẽ thành công.\n",
            "đời người chốn nào cũng có cảnh đẹp, sao không lựa lúc thích hợp mà đứng lại thưởng ngoạn? đừng mong muốn được đứng trên đỉnh núi cao mà ngắm nhìn đất trời, bởi núi khác cao còn có núi khác cao còn có gì là quá cao mà thôi. đời người chẳng có gì tầm mắt thứ đều có gì là chụp mơ thì chúng ta thắp lên núi nào mà \"nước mắt ngưỡng mộ nhau.\n",
            "0.5376629427155603\n",
            "Input: 时 间 的 步 伐 有 三 种 ： 未 来 姗 姗 来 迟 ， 现 在 像 箭 一 般 飞 逝 ， 过 去 永 远 静 立 不 动 。\n",
            "Predicted translation: tốc độ của dòng chảy thời gian được phân làm ba loại: một giấc thong dong đến muộn, một hiện tại vụt trôi như tên bay và một quá khứ mãi mãi mãi mãi đứng yên bất động.\n",
            "tốc độ của dòng chảy thời gian được phân làm ba loại: một tương lai thong dong đến muộn, một hiện tại vụt trôi như tên bay và một quá khứ mãi mãi đứng yên bất động.\n",
            "tốc độ của dòng chảy thời gian được phân làm ba loại: một giấc thong dong đến muộn, một hiện tại vụt trôi như tên bay và một quá khứ mãi mãi mãi mãi đứng yên bất động.\n",
            "0.8673341788994613\n",
            "Input: 现 在 的 你 要 是 多 学 一 样 本 事 ， 以 后 的 你 就 能 少 说 一 句 求 人 的 话 。\n",
            "Predicted translation: nếu hiện tại bạn cố gắng rèn luyện bản lĩnh thêm một phần thì chính bạn sau này sẽ bớt được một lần đi cầu xin người khác giúp đỡ.\n",
            "nếu hiện tại bạn cố gắng rèn luyện bản lĩnh thêm một phần thì chính bạn sau này sẽ bớt được một lần đi cầu xin người khác giúp đỡ.\n",
            "nếu hiện tại bạn cố gắng rèn luyện bản lĩnh thêm một phần thì chính bạn sau này sẽ bớt được một lần đi cầu xin người khác giúp đỡ.\n",
            "1.0\n",
            "Input: 创 造 明 天 的 是 今 天 ， 创 造 将 来 的 是 眼 前 ， 当 你 痴 痴 地 坐 等 将 来 的 时 候 ， 将 来 就 从 你 懒 惰 的 双 手 中 畸 形 丑 陋 地 走 出 来 。\n",
            "Predicted translation: điều sáng tạo nên ngày mai chính là hôm nay và điều làm nên tương lai chính là những gì đang hiện diện ngay trước mắt. khi bạn đang ngồi ngây ngốc chờ đợi tương lai đến thì tương lai sẽ bị sự lười nhác của bạn làm cho biến dạng xấu xí.\n",
            "điều sáng tạo nên ngày mai chính là hôm nay và điều làm nên tương lai chính là những gì đang hiện diện ngay trước mắt. khi bạn đang ngồi ngây ngốc chờ đợi tương lai đến thì tương lai sẽ bị sự lười nhác của bạn làm cho biến dạng xấu xí.\n",
            "điều sáng tạo nên ngày mai chính là hôm nay và điều làm nên tương lai chính là những gì đang hiện diện ngay trước mắt. khi bạn đang ngồi ngây ngốc chờ đợi tương lai đến thì tương lai sẽ bị sự lười nhác của bạn làm cho biến dạng xấu xí.\n",
            "1.0\n",
            "0.709380175816601\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}